{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ac0ecf7f",
   "metadata": {},
   "source": [
    "# Finding the Treatment Group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3d98a84a-3406-4c37-a81a-bac2e75cce43",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [9]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtest\u001b[49m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'test' is not defined"
     ]
    }
   ],
   "source": [
    "test "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d912856a",
   "metadata": {},
   "source": [
    "Pre requisites\n",
    "1. config.py in the config folder in the following format\n",
    "ACCESS_TOKEN = \"ghp_xxxx\"\n",
    "GITHUB_TOKEN = \"github_pat_xxxxx\"\n",
    "2. data folder where all data will be stored"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e3ecae2",
   "metadata": {},
   "source": [
    "#### Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1589b178-0df4-46f7-843a-bcbc09de9042",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "!pip install langdetect\n",
    "!pip install fuzzywuzzy\n",
    "!pip install python-Levenshtein\n",
    "!pip install graphqlclient\n",
    "!pip install lingua-language-detector\n",
    "!pip install spacy pandas spacy-langdetect\n",
    "!python -m spacy download en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47f5c8cd-de5f-4517-9a9d-2c520904ba6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3c3f448e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import os\n",
    "import sys\n",
    "from config import config\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7ce46e86",
   "metadata": {},
   "outputs": [],
   "source": [
    "access_token = config.ACCESS_TOKEN\n",
    "github_token = config.GITHUB_TOKEN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10b964f3",
   "metadata": {},
   "source": [
    "#### Download the example file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1fad7092",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File downloaded successfully and saved to data/2023-04-01-15.json.gz\n"
     ]
    }
   ],
   "source": [
    "# Ensure the 'data' folder exists\n",
    "if not os.path.exists('data'):\n",
    "    os.makedirs('data')\n",
    "\n",
    "url = 'https://data.gharchive.org/2023-04-01-15.json.gz'\n",
    "file_path = os.path.join('data', '2023-04-01-15.json.gz')\n",
    "\n",
    "# Check if the file already exists\n",
    "if os.path.exists(file_path):\n",
    "    print(f\"The file already exists at {file_path}. No need to download.\")\n",
    "else:\n",
    "    response = requests.get(url, stream=True)\n",
    "    # Check if the request was successful (HTTP Status Code 200)\n",
    "    if response.status_code == 200:\n",
    "        # Write the file\n",
    "        with open(file_path, 'wb') as file:\n",
    "            for chunk in response.iter_content(chunk_size=128):\n",
    "                file.write(chunk)\n",
    "        print(f\"File downloaded successfully and saved to {file_path}\")\n",
    "    else:\n",
    "        print(\"Failed to fetch the file\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f25880f0",
   "metadata": {},
   "source": [
    "#### read it in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8fb9ff13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>type</th>\n",
       "      <th>actor</th>\n",
       "      <th>repo</th>\n",
       "      <th>payload</th>\n",
       "      <th>public</th>\n",
       "      <th>created_at</th>\n",
       "      <th>org</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>28137501092</td>\n",
       "      <td>PushEvent</td>\n",
       "      <td>{'id': 41898282, 'login': 'github-actions[bot]...</td>\n",
       "      <td>{'id': 568277185, 'name': 'stdlib-js/strided-b...</td>\n",
       "      <td>{'repository_id': 568277185, 'push_id': 131547...</td>\n",
       "      <td>True</td>\n",
       "      <td>2023-04-01 15:00:00+00:00</td>\n",
       "      <td>{'id': 17805691, 'login': 'stdlib-js', 'gravat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>28137501094</td>\n",
       "      <td>CreateEvent</td>\n",
       "      <td>{'id': 115239975, 'login': 'ishuduwal', 'displ...</td>\n",
       "      <td>{'id': 622248753, 'name': 'ishuduwal/personal-...</td>\n",
       "      <td>{'ref': 'main', 'ref_type': 'branch', 'master_...</td>\n",
       "      <td>True</td>\n",
       "      <td>2023-04-01 15:00:00+00:00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28137501097</td>\n",
       "      <td>CreateEvent</td>\n",
       "      <td>{'id': 50960481, 'login': 'bxbao87', 'display_...</td>\n",
       "      <td>{'id': 622248756, 'name': 'bxbao87/bloglist', ...</td>\n",
       "      <td>{'ref': 'main', 'ref_type': 'branch', 'master_...</td>\n",
       "      <td>True</td>\n",
       "      <td>2023-04-01 15:00:00+00:00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>28137501098</td>\n",
       "      <td>PushEvent</td>\n",
       "      <td>{'id': 52915358, 'login': 'alwaz-shahid', 'dis...</td>\n",
       "      <td>{'id': 622201481, 'name': 'alwaz-shahid/extens...</td>\n",
       "      <td>{'repository_id': 622201481, 'push_id': 131547...</td>\n",
       "      <td>True</td>\n",
       "      <td>2023-04-01 15:00:00+00:00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28137501099</td>\n",
       "      <td>CreateEvent</td>\n",
       "      <td>{'id': 101326737, 'login': 'HOVADOVOLE', 'disp...</td>\n",
       "      <td>{'id': 622248605, 'name': 'HOVADOVOLE/Serial-P...</td>\n",
       "      <td>{'ref': 'main', 'ref_type': 'branch', 'master_...</td>\n",
       "      <td>True</td>\n",
       "      <td>2023-04-01 15:00:00+00:00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            id         type  \\\n",
       "0  28137501092    PushEvent   \n",
       "1  28137501094  CreateEvent   \n",
       "2  28137501097  CreateEvent   \n",
       "3  28137501098    PushEvent   \n",
       "4  28137501099  CreateEvent   \n",
       "\n",
       "                                               actor  \\\n",
       "0  {'id': 41898282, 'login': 'github-actions[bot]...   \n",
       "1  {'id': 115239975, 'login': 'ishuduwal', 'displ...   \n",
       "2  {'id': 50960481, 'login': 'bxbao87', 'display_...   \n",
       "3  {'id': 52915358, 'login': 'alwaz-shahid', 'dis...   \n",
       "4  {'id': 101326737, 'login': 'HOVADOVOLE', 'disp...   \n",
       "\n",
       "                                                repo  \\\n",
       "0  {'id': 568277185, 'name': 'stdlib-js/strided-b...   \n",
       "1  {'id': 622248753, 'name': 'ishuduwal/personal-...   \n",
       "2  {'id': 622248756, 'name': 'bxbao87/bloglist', ...   \n",
       "3  {'id': 622201481, 'name': 'alwaz-shahid/extens...   \n",
       "4  {'id': 622248605, 'name': 'HOVADOVOLE/Serial-P...   \n",
       "\n",
       "                                             payload  public  \\\n",
       "0  {'repository_id': 568277185, 'push_id': 131547...    True   \n",
       "1  {'ref': 'main', 'ref_type': 'branch', 'master_...    True   \n",
       "2  {'ref': 'main', 'ref_type': 'branch', 'master_...    True   \n",
       "3  {'repository_id': 622201481, 'push_id': 131547...    True   \n",
       "4  {'ref': 'main', 'ref_type': 'branch', 'master_...    True   \n",
       "\n",
       "                 created_at                                                org  \n",
       "0 2023-04-01 15:00:00+00:00  {'id': 17805691, 'login': 'stdlib-js', 'gravat...  \n",
       "1 2023-04-01 15:00:00+00:00                                                NaN  \n",
       "2 2023-04-01 15:00:00+00:00                                                NaN  \n",
       "3 2023-04-01 15:00:00+00:00                                                NaN  \n",
       "4 2023-04-01 15:00:00+00:00                                                NaN  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunk_size = 10000  # Adjust based on your system's memory\n",
    "chunks = []\n",
    "for chunk in pd.read_json(\"data/2023-04-01-15.json.gz\", lines=True, chunksize=chunk_size):\n",
    "    # Process the chunk of data here if possible\n",
    "    chunks.append(chunk)\n",
    "\n",
    "# If needed, concatenate chunks back into a single DataFrame\n",
    "df = pd.concat(chunks, ignore_index=True)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b77a69d",
   "metadata": {},
   "source": [
    "## 1. Identifying user location based on their GitHub profiles information\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fed77c0",
   "metadata": {},
   "source": [
    "####  GraphQL for batch requests to fetch data for multiple users in one request instead of making a request for each user and constantly hitting the rate limit for the REST API\n",
    "1. GraphQL Test: Creates data subset, constructs/executes GraphQL query for user locations\n",
    "2. Italian Identification: Uses Italian keywords to filter and display Italian users\n",
    "- subset of 500 Users >> 3 Italians identified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aa81dd6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>type</th>\n",
       "      <th>actor</th>\n",
       "      <th>repo</th>\n",
       "      <th>payload</th>\n",
       "      <th>public</th>\n",
       "      <th>created_at</th>\n",
       "      <th>org</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>28137501092</td>\n",
       "      <td>PushEvent</td>\n",
       "      <td>{'id': 41898282, 'login': 'github-actions[bot]...</td>\n",
       "      <td>{'id': 568277185, 'name': 'stdlib-js/strided-b...</td>\n",
       "      <td>{'repository_id': 568277185, 'push_id': 131547...</td>\n",
       "      <td>True</td>\n",
       "      <td>2023-04-01 15:00:00+00:00</td>\n",
       "      <td>{'id': 17805691, 'login': 'stdlib-js', 'gravat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>28137501094</td>\n",
       "      <td>CreateEvent</td>\n",
       "      <td>{'id': 115239975, 'login': 'ishuduwal', 'displ...</td>\n",
       "      <td>{'id': 622248753, 'name': 'ishuduwal/personal-...</td>\n",
       "      <td>{'ref': 'main', 'ref_type': 'branch', 'master_...</td>\n",
       "      <td>True</td>\n",
       "      <td>2023-04-01 15:00:00+00:00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28137501097</td>\n",
       "      <td>CreateEvent</td>\n",
       "      <td>{'id': 50960481, 'login': 'bxbao87', 'display_...</td>\n",
       "      <td>{'id': 622248756, 'name': 'bxbao87/bloglist', ...</td>\n",
       "      <td>{'ref': 'main', 'ref_type': 'branch', 'master_...</td>\n",
       "      <td>True</td>\n",
       "      <td>2023-04-01 15:00:00+00:00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>28137501098</td>\n",
       "      <td>PushEvent</td>\n",
       "      <td>{'id': 52915358, 'login': 'alwaz-shahid', 'dis...</td>\n",
       "      <td>{'id': 622201481, 'name': 'alwaz-shahid/extens...</td>\n",
       "      <td>{'repository_id': 622201481, 'push_id': 131547...</td>\n",
       "      <td>True</td>\n",
       "      <td>2023-04-01 15:00:00+00:00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28137501099</td>\n",
       "      <td>CreateEvent</td>\n",
       "      <td>{'id': 101326737, 'login': 'HOVADOVOLE', 'disp...</td>\n",
       "      <td>{'id': 622248605, 'name': 'HOVADOVOLE/Serial-P...</td>\n",
       "      <td>{'ref': 'main', 'ref_type': 'branch', 'master_...</td>\n",
       "      <td>True</td>\n",
       "      <td>2023-04-01 15:00:00+00:00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            id         type  \\\n",
       "0  28137501092    PushEvent   \n",
       "1  28137501094  CreateEvent   \n",
       "2  28137501097  CreateEvent   \n",
       "3  28137501098    PushEvent   \n",
       "4  28137501099  CreateEvent   \n",
       "\n",
       "                                               actor  \\\n",
       "0  {'id': 41898282, 'login': 'github-actions[bot]...   \n",
       "1  {'id': 115239975, 'login': 'ishuduwal', 'displ...   \n",
       "2  {'id': 50960481, 'login': 'bxbao87', 'display_...   \n",
       "3  {'id': 52915358, 'login': 'alwaz-shahid', 'dis...   \n",
       "4  {'id': 101326737, 'login': 'HOVADOVOLE', 'disp...   \n",
       "\n",
       "                                                repo  \\\n",
       "0  {'id': 568277185, 'name': 'stdlib-js/strided-b...   \n",
       "1  {'id': 622248753, 'name': 'ishuduwal/personal-...   \n",
       "2  {'id': 622248756, 'name': 'bxbao87/bloglist', ...   \n",
       "3  {'id': 622201481, 'name': 'alwaz-shahid/extens...   \n",
       "4  {'id': 622248605, 'name': 'HOVADOVOLE/Serial-P...   \n",
       "\n",
       "                                             payload  public  \\\n",
       "0  {'repository_id': 568277185, 'push_id': 131547...    True   \n",
       "1  {'ref': 'main', 'ref_type': 'branch', 'master_...    True   \n",
       "2  {'ref': 'main', 'ref_type': 'branch', 'master_...    True   \n",
       "3  {'repository_id': 622201481, 'push_id': 131547...    True   \n",
       "4  {'ref': 'main', 'ref_type': 'branch', 'master_...    True   \n",
       "\n",
       "                 created_at                                                org  \n",
       "0 2023-04-01 15:00:00+00:00  {'id': 17805691, 'login': 'stdlib-js', 'gravat...  \n",
       "1 2023-04-01 15:00:00+00:00                                                NaN  \n",
       "2 2023-04-01 15:00:00+00:00                                                NaN  \n",
       "3 2023-04-01 15:00:00+00:00                                                NaN  \n",
       "4 2023-04-01 15:00:00+00:00                                                NaN  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define batch size\n",
    "BATCH_SIZE = 800  # Choose a reasonable size that avoids timeouts but minimizes the number of requests\n",
    "\n",
    "def sanitize_for_alias(name):\n",
    "    valid_starters = set(\"abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ_\")\n",
    "    sanitized_name = ''.join(ch if ch.isalnum() else '_' for ch in name)\n",
    "    if sanitized_name[0] not in valid_starters:\n",
    "        sanitized_name = 'a' + sanitized_name\n",
    "    return sanitized_name\n",
    "\n",
    "def construct_query(logins_batch):\n",
    "    query_parts = [\n",
    "        f'''\n",
    "        {sanitize_for_alias(login)}: user(login: \"{login}\") {{\n",
    "            location\n",
    "        }}\n",
    "        ''' for login in logins_batch\n",
    "    ]\n",
    "    return '{' + ''.join(query_parts) + '}'\n",
    "\n",
    "def fetch_data(query, github_token):\n",
    "    headers = {\n",
    "        'Authorization': 'bearer ' + github_token,\n",
    "        'Content-Type': 'application/json'\n",
    "    }\n",
    "    response = requests.post('https://api.github.com/graphql', json={'query': query}, headers=headers)\n",
    "    response_json = response.json()\n",
    "\n",
    "    if response_json is None:\n",
    "        raise Exception(\"No response from API\")\n",
    "    if 'data' not in response_json:\n",
    "        raise Exception(\"Data key missing from response:\", response_json)\n",
    "    \n",
    "    return response_json['data']\n",
    "\n",
    "def update_location(data):\n",
    "    if data is None:\n",
    "        print(\"No data to update.\")\n",
    "        return\n",
    "    \n",
    "    for login, user_data in data.items():\n",
    "        if user_data is None:\n",
    "            #print(f\"No data for user: {login}\")\n",
    "            continue\n",
    "        location = user_data.get('location', None)\n",
    "        mask = df['actor'].apply(lambda x: x['login']) == login\n",
    "        df.loc[mask, 'actor'] = df.loc[mask, 'actor'].apply(\n",
    "            lambda x: {**x, 'location': location}\n",
    "        )\n",
    "\n",
    "# Get unique logins\n",
    "logins = df['actor'].apply(lambda x: x['login']).unique().tolist()\n",
    "logins = [login for login in logins if not login[0].isdigit()]\n",
    "\n",
    "# A dictionary to store fetched locations\n",
    "locations = {}\n",
    "\n",
    "# Divide logins into batches and fetch data for each batch\n",
    "for i in range(0, len(logins), BATCH_SIZE):\n",
    "    logins_batch = logins[i:i + BATCH_SIZE]\n",
    "    query = construct_query(logins_batch)\n",
    "    data = fetch_data(query, github_token)\n",
    "    \n",
    "    # Update the locations dictionary instead of the DataFrame directly\n",
    "    for login, user_data in data.items():\n",
    "        if user_data is not None:\n",
    "            locations[login] = user_data.get('location', None)\n",
    "    \n",
    "    # Consider adding a sleep to avoid hitting rate limits\n",
    "    time.sleep(1)\n",
    "\n",
    "# Update the DataFrame in a vectorized manner\n",
    "df['actor'] = df['actor'].apply(\n",
    "    lambda x: {**x, 'location': locations.get(x['login'], None)} if x['login'] in locations else x\n",
    ")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "21512bf3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    {'id': 41898282, 'login': 'github-actions[bot]...\n",
       "1    {'id': 115239975, 'login': 'ishuduwal', 'displ...\n",
       "2    {'id': 50960481, 'login': 'bxbao87', 'display_...\n",
       "3    {'id': 52915358, 'login': 'alwaz-shahid', 'dis...\n",
       "4    {'id': 101326737, 'login': 'HOVADOVOLE', 'disp...\n",
       "Name: actor, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"actor\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "506aa1bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>login</th>\n",
       "      <th>display_login</th>\n",
       "      <th>gravatar_id</th>\n",
       "      <th>url</th>\n",
       "      <th>avatar_url</th>\n",
       "      <th>location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16925025</td>\n",
       "      <td>maffo102</td>\n",
       "      <td>maffo102</td>\n",
       "      <td></td>\n",
       "      <td>https://api.github.com/users/maffo102</td>\n",
       "      <td>https://avatars.githubusercontent.com/u/16925025?</td>\n",
       "      <td>Italy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30238962</td>\n",
       "      <td>merkleID</td>\n",
       "      <td>merkleID</td>\n",
       "      <td></td>\n",
       "      <td>https://api.github.com/users/merkleID</td>\n",
       "      <td>https://avatars.githubusercontent.com/u/30238962?</td>\n",
       "      <td>milan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>117077787</td>\n",
       "      <td>Nelexiad</td>\n",
       "      <td>Nelexiad</td>\n",
       "      <td></td>\n",
       "      <td>https://api.github.com/users/Nelexiad</td>\n",
       "      <td>https://avatars.githubusercontent.com/u/117077...</td>\n",
       "      <td>Palermo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>99094086</td>\n",
       "      <td>CrisLap</td>\n",
       "      <td>CrisLap</td>\n",
       "      <td></td>\n",
       "      <td>https://api.github.com/users/CrisLap</td>\n",
       "      <td>https://avatars.githubusercontent.com/u/99094086?</td>\n",
       "      <td>Verona, Italy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>84925446</td>\n",
       "      <td>davidetacchini</td>\n",
       "      <td>davidetacchini</td>\n",
       "      <td></td>\n",
       "      <td>https://api.github.com/users/davidetacchini</td>\n",
       "      <td>https://avatars.githubusercontent.com/u/84925446?</td>\n",
       "      <td>Italy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id           login   display_login gravatar_id  \\\n",
       "0   16925025        maffo102        maffo102               \n",
       "1   30238962        merkleID        merkleID               \n",
       "2  117077787        Nelexiad        Nelexiad               \n",
       "3   99094086         CrisLap         CrisLap               \n",
       "4   84925446  davidetacchini  davidetacchini               \n",
       "\n",
       "                                           url  \\\n",
       "0        https://api.github.com/users/maffo102   \n",
       "1        https://api.github.com/users/merkleID   \n",
       "2        https://api.github.com/users/Nelexiad   \n",
       "3         https://api.github.com/users/CrisLap   \n",
       "4  https://api.github.com/users/davidetacchini   \n",
       "\n",
       "                                          avatar_url       location  \n",
       "0  https://avatars.githubusercontent.com/u/16925025?          Italy  \n",
       "1  https://avatars.githubusercontent.com/u/30238962?          milan  \n",
       "2  https://avatars.githubusercontent.com/u/117077...        Palermo  \n",
       "3  https://avatars.githubusercontent.com/u/99094086?  Verona, Italy  \n",
       "4  https://avatars.githubusercontent.com/u/84925446?          Italy  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from fuzzywuzzy import process\n",
    "\n",
    "# List of major cities in Italy and other possible indications of an Italian location\n",
    "italian_keywords = [\n",
    "    \"rome\", \"roma\", \"milan\", \"milano\", \"naples\", \"napoli\", \"turin\", \"torino\", \"palermo\", \n",
    "    \"genoa\", \"genova\", \"bologna\", \"florence\", \"firenze\", \"venice\", \"venezia\", \"verona\", \n",
    "    \"cagliari\", \"parma\", \"ferrara\", \"treviso\", \"padua\", \"padova\", \"trieste\", \"taranto\", \n",
    "    \"brescia\", \"prato\", \"modena\", \"reggio\", \"calabria\", \"emilia\", \"perugia\", \"livorno\", \n",
    "    \"ravenna\", \"foggia\", \"rimini\", \"salerno\", \"sassari\", \"latina\", \"giugliano\", \"tuscany\", \n",
    "    \"toscana\", \"sicily\", \"sicilia\", \"sardinia\", \"sardegna\", \"lombardy\", \"lombardia\", \"piedmont\", \n",
    "    \"piemonte\", \"liguria\", \"calabria\", \"umbria\", \"marche\", \"abruzzo\", \"italy\", \"italia\"\n",
    "    ]\n",
    "\n",
    "def is_italian_location(location):\n",
    "    if pd.isna(location):\n",
    "        return False\n",
    "    location = location.lower()\n",
    "    if any(keyword in location for keyword in italian_keywords):\n",
    "        return True\n",
    "    \n",
    "    # Check if the location has alphanumeric content before attempting fuzzy matching\n",
    "    if any(char.isalnum() for char in location):\n",
    "        closest_match, score = process.extractOne(location, italian_keywords)\n",
    "        return score > 80\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "# Assuming df is defined and contains the relevant data\n",
    "# Avoid computing the condition multiple times by storing it in a variable\n",
    "is_italian_mask = df['actor'].apply(lambda x: is_italian_location(x.get('location')))\n",
    "\n",
    "# Filter out rows with Italian locations\n",
    "non_italian_df = df[~is_italian_mask]\n",
    "# Filter in rows with Italian locations\n",
    "italian_df = df[is_italian_mask]\n",
    "\n",
    "# Flatten the 'actor' column from the italian_df\n",
    "flattened_italian_actor_df = pd.json_normalize(italian_df['actor'].tolist())\n",
    "\n",
    "# Display the flattened 'actor' column\n",
    "flattened_italian_actor_df.to_csv('data/flattened_italian_actor_df.csv', index=False)\n",
    "flattened_italian_actor_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3f7c7c3",
   "metadata": {},
   "source": [
    "-------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13e72d85",
   "metadata": {},
   "source": [
    "## 2. E-Mail ends with .it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "088d56c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming you have a dataframe df with a \"payload\" column\n",
    "# Create a new dataframe with extracted commit information\n",
    "def extract_commit_info(payload):\n",
    "    if 'commits' in payload:\n",
    "        commits = payload['commits']\n",
    "        if commits:\n",
    "            first_commit = commits[0]\n",
    "            return {\n",
    "                'repository_id': payload.get('repository_id'),\n",
    "                'push_id': payload.get('push_id'),\n",
    "                'author_email': first_commit['author']['email'],\n",
    "                'author_name': first_commit['author']['name'],\n",
    "                'commit_message': first_commit['message'],\n",
    "                'commit_sha': first_commit['sha']\n",
    "            }\n",
    "    return None\n",
    "\n",
    "# Apply the function to the \"payload\" column to extract commit information\n",
    "df['commit_info'] = df['payload'].apply(extract_commit_info)\n",
    "\n",
    "# Filter out None entries before applying Series constructor\n",
    "non_none_commit_info = df['commit_info'][df['commit_info'].notna()]\n",
    "\n",
    "# Create a new dataframe from the non-None extracted information\n",
    "df_commit_info = non_none_commit_info.apply(pd.Series)\n",
    "\n",
    "# Now df_commit_info contains the extracted commit information\n",
    "italian_emails = df_commit_info.copy()\n",
    "\n",
    "# Remove NANs\n",
    "italian_emails = italian_emails.dropna(subset=['author_email', 'author_name', 'repository_id'])\n",
    "\n",
    "# Ensure email column is string type\n",
    "italian_emails['author_email'] = italian_emails['author_email'].astype(str)\n",
    "\n",
    "# Filter for Italian emails\n",
    "email_address_it = italian_emails[italian_emails['author_email'].str.endswith('.it')]\n",
    "\n",
    "email_address_it.to_csv('data/email_address_it.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bd63047a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 154 entries, 1465 to 159465\n",
      "Data columns (total 6 columns):\n",
      " #   Column          Non-Null Count  Dtype \n",
      "---  ------          --------------  ----- \n",
      " 0   repository_id   154 non-null    int64 \n",
      " 1   push_id         154 non-null    int64 \n",
      " 2   author_email    154 non-null    object\n",
      " 3   author_name     154 non-null    object\n",
      " 4   commit_message  154 non-null    object\n",
      " 5   commit_sha      154 non-null    object\n",
      "dtypes: int64(2), object(4)\n",
      "memory usage: 8.4+ KB\n"
     ]
    }
   ],
   "source": [
    "email_address_it.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11543b26",
   "metadata": {},
   "source": [
    "## 3. Analyzing org descriptions\n",
    "Use GraphQL to get more information at once"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dca2e6d8",
   "metadata": {},
   "source": [
    "!pip install aiohttp\n",
    "!pip install asyncio\n",
    "!pip install nest_asyncio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "d98a8ce9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: [{'type': 'NOT_FOUND', 'path': ['org37'], 'locations': [{'line': 187, 'column': 9}], 'message': \"Could not resolve to an Organization with the login of 'RBFLabs'.\"}, {'type': 'NOT_FOUND', 'path': ['org90'], 'locations': [{'line': 452, 'column': 9}], 'message': \"Could not resolve to an Organization with the login of '022SE-WI22'.\"}, {'type': 'NOT_FOUND', 'path': ['org120'], 'locations': [{'line': 602, 'column': 9}], 'message': \"Could not resolve to an Organization with the login of 'FZM-Technologies'.\"}, {'type': 'NOT_FOUND', 'path': ['org270'], 'locations': [{'line': 1352, 'column': 9}], 'message': \"Could not resolve to an Organization with the login of 'chainparrot'.\"}, {'type': 'NOT_FOUND', 'path': ['org406'], 'locations': [{'line': 2032, 'column': 9}], 'message': \"Could not resolve to an Organization with the login of 'playing-ground'.\"}, {'type': 'NOT_FOUND', 'path': ['org468'], 'locations': [{'line': 2342, 'column': 9}], 'message': \"Could not resolve to an Organization with the login of 'keptn-demo-live'.\"}]\n",
      "Warning: [{'type': 'NOT_FOUND', 'path': ['org27'], 'locations': [{'line': 137, 'column': 9}], 'message': \"Could not resolve to an Organization with the login of 'Strada1'.\"}, {'type': 'NOT_FOUND', 'path': ['org29'], 'locations': [{'line': 147, 'column': 9}], 'message': \"Could not resolve to an Organization with the login of 'iruoy-nl'.\"}, {'type': 'NOT_FOUND', 'path': ['org49'], 'locations': [{'line': 247, 'column': 9}], 'message': \"Could not resolve to an Organization with the login of 'eras-fyi'.\"}, {'type': 'NOT_FOUND', 'path': ['org65'], 'locations': [{'line': 327, 'column': 9}], 'message': \"Could not resolve to an Organization with the login of 'DataFest-2023-Algo-Rhythms'.\"}, {'type': 'NOT_FOUND', 'path': ['org83'], 'locations': [{'line': 417, 'column': 9}], 'message': \"Could not resolve to an Organization with the login of 'codesquad2023-fe-algorithm'.\"}, {'type': 'NOT_FOUND', 'path': ['org172'], 'locations': [{'line': 862, 'column': 9}], 'message': \"Could not resolve to an Organization with the login of 'Polls-team'.\"}, {'type': 'NOT_FOUND', 'path': ['org176'], 'locations': [{'line': 882, 'column': 9}], 'message': \"Could not resolve to an Organization with the login of 'coders-app'.\"}, {'type': 'NOT_FOUND', 'path': ['org233'], 'locations': [{'line': 1167, 'column': 9}], 'message': \"Could not resolve to an Organization with the login of 'xManager-App'.\"}, {'type': 'NOT_FOUND', 'path': ['org265'], 'locations': [{'line': 1327, 'column': 9}], 'message': \"Could not resolve to an Organization with the login of 'new-ai-company'.\"}, {'type': 'NOT_FOUND', 'path': ['org283'], 'locations': [{'line': 1417, 'column': 9}], 'message': \"Could not resolve to an Organization with the login of 'CodeCommun-co'.\"}, {'type': 'NOT_FOUND', 'path': ['org295'], 'locations': [{'line': 1477, 'column': 9}], 'message': \"Could not resolve to an Organization with the login of 'MAJigsaws-Storage'.\"}, {'type': 'NOT_FOUND', 'path': ['org409'], 'locations': [{'line': 2047, 'column': 9}], 'message': \"Could not resolve to an Organization with the login of 'MJU-Coin'.\"}, {'type': 'NOT_FOUND', 'path': ['org416'], 'locations': [{'line': 2082, 'column': 9}], 'message': \"Could not resolve to an Organization with the login of 'rgmflag'.\"}, {'type': 'NOT_FOUND', 'path': ['org493'], 'locations': [{'line': 2467, 'column': 9}], 'message': \"Could not resolve to an Organization with the login of 'Wizer-Community'.\"}]\n",
      "Warning: [{'type': 'NOT_FOUND', 'path': ['org117'], 'locations': [{'line': 587, 'column': 9}], 'message': \"Could not resolve to an Organization with the login of 'porn-vault'.\"}, {'type': 'NOT_FOUND', 'path': ['org225'], 'locations': [{'line': 1127, 'column': 9}], 'message': \"Could not resolve to an Organization with the login of 'KJSCE-Hack-7-0'.\"}, {'type': 'NOT_FOUND', 'path': ['org263'], 'locations': [{'line': 1317, 'column': 9}], 'message': \"Could not resolve to an Organization with the login of 'smartive-education'.\"}, {'type': 'NOT_FOUND', 'path': ['org284'], 'locations': [{'line': 1422, 'column': 9}], 'message': \"Could not resolve to an Organization with the login of 'YunP4nSec'.\"}, {'type': 'NOT_FOUND', 'path': ['org352'], 'locations': [{'line': 1762, 'column': 9}], 'message': \"Could not resolve to an Organization with the login of 'Meta-Front-End-Developer-PC'.\"}, {'type': 'NOT_FOUND', 'path': ['org431'], 'locations': [{'line': 2157, 'column': 9}], 'message': \"Could not resolve to an Organization with the login of 'XBSX2-Group'.\"}]\n",
      "Warning: [{'type': 'NOT_FOUND', 'path': ['org39'], 'locations': [{'line': 197, 'column': 9}], 'message': \"Could not resolve to an Organization with the login of 'DarkThroneReborn'.\"}, {'type': 'NOT_FOUND', 'path': ['org55'], 'locations': [{'line': 277, 'column': 9}], 'message': \"Could not resolve to an Organization with the login of 'AlkalineCrystalNetwork'.\"}, {'type': 'NOT_FOUND', 'path': ['org97'], 'locations': [{'line': 487, 'column': 9}], 'message': \"Could not resolve to an Organization with the login of 'MiSa-Com'.\"}, {'type': 'NOT_FOUND', 'path': ['org134'], 'locations': [{'line': 672, 'column': 9}], 'message': \"Could not resolve to an Organization with the login of 'hpccbk'.\"}, {'type': 'NOT_FOUND', 'path': ['org157'], 'locations': [{'line': 787, 'column': 9}], 'message': \"Could not resolve to an Organization with the login of 'flowforge'.\"}, {'type': 'NOT_FOUND', 'path': ['org167'], 'locations': [{'line': 837, 'column': 9}], 'message': \"Could not resolve to an Organization with the login of 'fullstackio'.\"}, {'type': 'NOT_FOUND', 'path': ['org174'], 'locations': [{'line': 872, 'column': 9}], 'message': \"Could not resolve to an Organization with the login of 'nstu-games'.\"}, {'type': 'NOT_FOUND', 'path': ['org258'], 'locations': [{'line': 1292, 'column': 9}], 'message': \"Could not resolve to an Organization with the login of 'foss-lodpm'.\"}, {'type': 'NOT_FOUND', 'path': ['org295'], 'locations': [{'line': 1477, 'column': 9}], 'message': \"Could not resolve to an Organization with the login of 'mix-labs'.\"}, {'type': 'NOT_FOUND', 'path': ['org452'], 'locations': [{'line': 2262, 'column': 9}], 'message': \"Could not resolve to an Organization with the login of 'jqassistant-contrib'.\"}, {'type': 'NOT_FOUND', 'path': ['org475'], 'locations': [{'line': 2377, 'column': 9}], 'message': \"Could not resolve to an Organization with the login of 'Wits-SD3-404-Effort-not-Found'.\"}, {'type': 'NOT_FOUND', 'path': ['org478'], 'locations': [{'line': 2392, 'column': 9}], 'message': \"Could not resolve to an Organization with the login of 'zkSocial-zklisbon'.\"}, {'type': 'NOT_FOUND', 'path': ['org498'], 'locations': [{'line': 2492, 'column': 9}], 'message': \"Could not resolve to an Organization with the login of 'PradoLang'.\"}]\n",
      "Warning: [{'type': 'NOT_FOUND', 'path': ['org19'], 'locations': [{'line': 97, 'column': 9}], 'message': \"Could not resolve to an Organization with the login of 'Armodia-Systems-LTD'.\"}, {'type': 'NOT_FOUND', 'path': ['org60'], 'locations': [{'line': 302, 'column': 9}], 'message': \"Could not resolve to an Organization with the login of '9Fork'.\"}, {'type': 'NOT_FOUND', 'path': ['org185'], 'locations': [{'line': 927, 'column': 9}], 'message': \"Could not resolve to an Organization with the login of 'codecyclecommunity'.\"}, {'type': 'NOT_FOUND', 'path': ['org188'], 'locations': [{'line': 942, 'column': 9}], 'message': \"Could not resolve to an Organization with the login of 'g4o2'.\"}, {'type': 'NOT_FOUND', 'path': ['org193'], 'locations': [{'line': 967, 'column': 9}], 'message': \"Could not resolve to an Organization with the login of 'linwalt'.\"}, {'type': 'NOT_FOUND', 'path': ['org202'], 'locations': [{'line': 1012, 'column': 9}], 'message': \"Could not resolve to an Organization with the login of 'ABA-Bank'.\"}, {'type': 'NOT_FOUND', 'path': ['org278'], 'locations': [{'line': 1392, 'column': 9}], 'message': \"Could not resolve to an Organization with the login of 'my-god-life'.\"}, {'type': 'NOT_FOUND', 'path': ['org295'], 'locations': [{'line': 1477, 'column': 9}], 'message': \"Could not resolve to an Organization with the login of 'equationsoftworks'.\"}, {'type': 'NOT_FOUND', 'path': ['org362'], 'locations': [{'line': 1812, 'column': 9}], 'message': \"Could not resolve to an Organization with the login of 'naomis-novas'.\"}, {'type': 'NOT_FOUND', 'path': ['org451'], 'locations': [{'line': 2257, 'column': 9}], 'message': \"Could not resolve to an Organization with the login of 'falsy-oss'.\"}]\n",
      "Warning: [{'type': 'NOT_FOUND', 'path': ['org134'], 'locations': [{'line': 672, 'column': 9}], 'message': \"Could not resolve to an Organization with the login of 'Fundacja-Sterczace-Uszy'.\"}, {'type': 'NOT_FOUND', 'path': ['org241'], 'locations': [{'line': 1207, 'column': 9}], 'message': \"Could not resolve to an Organization with the login of 'projetobarbeiro'.\"}, {'type': 'NOT_FOUND', 'path': ['org247'], 'locations': [{'line': 1237, 'column': 9}], 'message': \"Could not resolve to an Organization with the login of 'TestForAutomation1337'.\"}, {'type': 'NOT_FOUND', 'path': ['org261'], 'locations': [{'line': 1307, 'column': 9}], 'message': \"Could not resolve to an Organization with the login of 'Figments-team'.\"}, {'type': 'NOT_FOUND', 'path': ['org313'], 'locations': [{'line': 1567, 'column': 9}], 'message': \"Could not resolve to an Organization with the login of 'Skilltechs'.\"}, {'type': 'NOT_FOUND', 'path': ['org345'], 'locations': [{'line': 1727, 'column': 9}], 'message': \"Could not resolve to an Organization with the login of 'TesouroNacional'.\"}, {'type': 'NOT_FOUND', 'path': ['org435'], 'locations': [{'line': 2177, 'column': 9}], 'message': \"Could not resolve to an Organization with the login of 'friending-com'.\"}, {'type': 'NOT_FOUND', 'path': ['org442'], 'locations': [{'line': 2212, 'column': 9}], 'message': \"Could not resolve to an Organization with the login of 'Community-Lores'.\"}, {'type': 'NOT_FOUND', 'path': ['org445'], 'locations': [{'line': 2227, 'column': 9}], 'message': \"Could not resolve to an Organization with the login of 'Zenesus'.\"}, {'type': 'NOT_FOUND', 'path': ['org467'], 'locations': [{'line': 2337, 'column': 9}], 'message': \"Could not resolve to an Organization with the login of 'qiandao-today'.\"}, {'type': 'NOT_FOUND', 'path': ['org483'], 'locations': [{'line': 2417, 'column': 9}], 'message': \"Could not resolve to an Organization with the login of 'NITKC22s'.\"}]\n",
      "Warning: [{'type': 'NOT_FOUND', 'path': ['org47'], 'locations': [{'line': 237, 'column': 9}], 'message': \"Could not resolve to an Organization with the login of 'scdt-china'.\"}, {'type': 'NOT_FOUND', 'path': ['org67'], 'locations': [{'line': 337, 'column': 9}], 'message': \"Could not resolve to an Organization with the login of 'EdgeSoftComputing'.\"}, {'type': 'NOT_FOUND', 'path': ['org158'], 'locations': [{'line': 792, 'column': 9}], 'message': \"Could not resolve to an Organization with the login of 'VS-GC23'.\"}, {'type': 'NOT_FOUND', 'path': ['org186'], 'locations': [{'line': 932, 'column': 9}], 'message': \"Could not resolve to an Organization with the login of 'MyProjectsAndTools'.\"}, {'type': 'NOT_FOUND', 'path': ['org273'], 'locations': [{'line': 1367, 'column': 9}], 'message': \"Could not resolve to an Organization with the login of 'open-academy'.\"}, {'type': 'NOT_FOUND', 'path': ['org288'], 'locations': [{'line': 1442, 'column': 9}], 'message': \"Could not resolve to an Organization with the login of 'QsadeSoft'.\"}, {'type': 'NOT_FOUND', 'path': ['org292'], 'locations': [{'line': 1462, 'column': 9}], 'message': \"Could not resolve to an Organization with the login of 'GithubAndDiscord-Testers'.\"}, {'type': 'NOT_FOUND', 'path': ['org326'], 'locations': [{'line': 1632, 'column': 9}], 'message': \"Could not resolve to an Organization with the login of 'VR-use'.\"}, {'type': 'NOT_FOUND', 'path': ['org439'], 'locations': [{'line': 2197, 'column': 9}], 'message': \"Could not resolve to an Organization with the login of 'hyonline-store'.\"}, {'type': 'NOT_FOUND', 'path': ['org446'], 'locations': [{'line': 2232, 'column': 9}], 'message': \"Could not resolve to an Organization with the login of 'pmall-neu'.\"}, {'type': 'NOT_FOUND', 'path': ['org497'], 'locations': [{'line': 2487, 'column': 9}], 'message': \"Could not resolve to an Organization with the login of 'Next-NestBoardPractice'.\"}]\n",
      "Warning: [{'type': 'NOT_FOUND', 'path': ['org237'], 'locations': [{'line': 1187, 'column': 9}], 'message': \"Could not resolve to an Organization with the login of 'JARP-Inc'.\"}, {'type': 'NOT_FOUND', 'path': ['org263'], 'locations': [{'line': 1317, 'column': 9}], 'message': \"Could not resolve to an Organization with the login of 'AISC-understanding-search'.\"}, {'type': 'NOT_FOUND', 'path': ['org267'], 'locations': [{'line': 1337, 'column': 9}], 'message': \"Could not resolve to an Organization with the login of 'ZephyrJS-Project'.\"}, {'type': 'NOT_FOUND', 'path': ['org392'], 'locations': [{'line': 1962, 'column': 9}], 'message': \"Could not resolve to an Organization with the login of 'drexsoftorg'.\"}]\n",
      "Warning: [{'type': 'NOT_FOUND', 'path': ['org199'], 'locations': [{'line': 997, 'column': 9}], 'message': \"Could not resolve to an Organization with the login of 'symbolverse'.\"}, {'type': 'NOT_FOUND', 'path': ['org292'], 'locations': [{'line': 1462, 'column': 9}], 'message': \"Could not resolve to an Organization with the login of 'Miku-UI-Snow-Edition'.\"}, {'type': 'NOT_FOUND', 'path': ['org364'], 'locations': [{'line': 1822, 'column': 9}], 'message': \"Could not resolve to an Organization with the login of 'blazor-spark'.\"}, {'type': 'NOT_FOUND', 'path': ['org371'], 'locations': [{'line': 1857, 'column': 9}], 'message': \"Could not resolve to an Organization with the login of 'FullMadAgilists'.\"}, {'type': 'NOT_FOUND', 'path': ['org421'], 'locations': [{'line': 2107, 'column': 9}], 'message': \"Could not resolve to an Organization with the login of 'Sura-framework'.\"}, {'type': 'NOT_FOUND', 'path': ['org457'], 'locations': [{'line': 2287, 'column': 9}], 'message': \"Could not resolve to an Organization with the login of 'COS301-MP-AboutTime'.\"}, {'type': 'NOT_FOUND', 'path': ['org476'], 'locations': [{'line': 2382, 'column': 9}], 'message': \"Could not resolve to an Organization with the login of 'TempleOS-Simplified'.\"}]\n",
      "Warning: [{'type': 'NOT_FOUND', 'path': ['org50'], 'locations': [{'line': 252, 'column': 9}], 'message': \"Could not resolve to an Organization with the login of 'dt-ca-demo'.\"}, {'type': 'NOT_FOUND', 'path': ['org63'], 'locations': [{'line': 317, 'column': 9}], 'message': \"Could not resolve to an Organization with the login of 'Nemesis-Games'.\"}, {'type': 'NOT_FOUND', 'path': ['org142'], 'locations': [{'line': 712, 'column': 9}], 'message': \"Could not resolve to an Organization with the login of 'Equipe-01-DSM-2023'.\"}, {'type': 'NOT_FOUND', 'path': ['org175'], 'locations': [{'line': 877, 'column': 9}], 'message': \"Could not resolve to an Organization with the login of 'alinesno-cloud'.\"}, {'type': 'NOT_FOUND', 'path': ['org224'], 'locations': [{'line': 1122, 'column': 9}], 'message': \"Could not resolve to an Organization with the login of 'GPTSwift'.\"}, {'type': 'NOT_FOUND', 'path': ['org252'], 'locations': [{'line': 1262, 'column': 9}], 'message': \"Could not resolve to an Organization with the login of 'GreenOneGame'.\"}, {'type': 'NOT_FOUND', 'path': ['org378'], 'locations': [{'line': 1892, 'column': 9}], 'message': \"Could not resolve to an Organization with the login of 'GamblApps'.\"}, {'type': 'NOT_FOUND', 'path': ['org464'], 'locations': [{'line': 2322, 'column': 9}], 'message': \"Could not resolve to an Organization with the login of 'xprobe-inc'.\"}]\n",
      "Warning: [{'type': 'NOT_FOUND', 'path': ['org43'], 'locations': [{'line': 217, 'column': 9}], 'message': \"Could not resolve to an Organization with the login of 'anrui2333'.\"}, {'type': 'NOT_FOUND', 'path': ['org101'], 'locations': [{'line': 507, 'column': 9}], 'message': \"Could not resolve to an Organization with the login of 'B1nary-Devs-3-Semestre'.\"}, {'type': 'NOT_FOUND', 'path': ['org151'], 'locations': [{'line': 757, 'column': 9}], 'message': \"Could not resolve to an Organization with the login of 'Healthcare-Application-IIITB'.\"}, {'type': 'NOT_FOUND', 'path': ['org255'], 'locations': [{'line': 1277, 'column': 9}], 'message': \"Could not resolve to an Organization with the login of 'Jalya3'.\"}, {'type': 'NOT_FOUND', 'path': ['org414'], 'locations': [{'line': 2072, 'column': 9}], 'message': \"Could not resolve to an Organization with the login of 'LocalGen-dev'.\"}, {'type': 'NOT_FOUND', 'path': ['org432'], 'locations': [{'line': 2162, 'column': 9}], 'message': \"Could not resolve to an Organization with the login of 'MCCrawler'.\"}, {'type': 'NOT_FOUND', 'path': ['org489'], 'locations': [{'line': 2447, 'column': 9}], 'message': \"Could not resolve to an Organization with the login of 'Team-Deadly'.\"}]\n",
      "Warning: [{'type': 'NOT_FOUND', 'path': ['org3'], 'locations': [{'line': 17, 'column': 9}], 'message': \"Could not resolve to an Organization with the login of 'greenfrogmc'.\"}, {'type': 'NOT_FOUND', 'path': ['org67'], 'locations': [{'line': 337, 'column': 9}], 'message': \"Could not resolve to an Organization with the login of 'traveli-dev'.\"}, {'type': 'NOT_FOUND', 'path': ['org110'], 'locations': [{'line': 552, 'column': 9}], 'message': \"Could not resolve to an Organization with the login of 'billboardoo'.\"}, {'type': 'NOT_FOUND', 'path': ['org156'], 'locations': [{'line': 782, 'column': 9}], 'message': \"Could not resolve to an Organization with the login of 'xogunato-kendo-londrina'.\"}, {'type': 'NOT_FOUND', 'path': ['org181'], 'locations': [{'line': 907, 'column': 9}], 'message': \"Could not resolve to an Organization with the login of 'Bugfish-Industries'.\"}, {'type': 'NOT_FOUND', 'path': ['org210'], 'locations': [{'line': 1052, 'column': 9}], 'message': \"Could not resolve to an Organization with the login of 'allmycal'.\"}, {'type': 'NOT_FOUND', 'path': ['org271'], 'locations': [{'line': 1357, 'column': 9}], 'message': \"Could not resolve to an Organization with the login of 'meshed-cloud'.\"}, {'type': 'NOT_FOUND', 'path': ['org295'], 'locations': [{'line': 1477, 'column': 9}], 'message': \"Could not resolve to an Organization with the login of 'MonthExam'.\"}, {'type': 'NOT_FOUND', 'path': ['org401'], 'locations': [{'line': 2007, 'column': 9}], 'message': \"Could not resolve to an Organization with the login of 'PeklaGames'.\"}, {'type': 'NOT_FOUND', 'path': ['org421'], 'locations': [{'line': 2107, 'column': 9}], 'message': \"Could not resolve to an Organization with the login of 'It-Team-2'.\"}, {'type': 'NOT_FOUND', 'path': ['org427'], 'locations': [{'line': 2137, 'column': 9}], 'message': \"Could not resolve to an Organization with the login of 'cs44e'.\"}]\n",
      "Warning: [{'type': 'NOT_FOUND', 'path': ['org45'], 'locations': [{'line': 227, 'column': 9}], 'message': \"Could not resolve to an Organization with the login of 'topaz-lang'.\"}, {'type': 'NOT_FOUND', 'path': ['org87'], 'locations': [{'line': 437, 'column': 9}], 'message': \"Could not resolve to an Organization with the login of 'practicum-com'.\"}, {'type': 'NOT_FOUND', 'path': ['org95'], 'locations': [{'line': 477, 'column': 9}], 'message': \"Could not resolve to an Organization with the login of 'trydevhub'.\"}, {'type': 'NOT_FOUND', 'path': ['org106'], 'locations': [{'line': 532, 'column': 9}], 'message': \"Could not resolve to an Organization with the login of '37iOS'.\"}, {'type': 'NOT_FOUND', 'path': ['org218'], 'locations': [{'line': 1092, 'column': 9}], 'message': \"Could not resolve to an Organization with the login of 'PearceRobotics'.\"}, {'type': 'NOT_FOUND', 'path': ['org253'], 'locations': [{'line': 1267, 'column': 9}], 'message': \"Could not resolve to an Organization with the login of 'bitzeroinc'.\"}, {'type': 'NOT_FOUND', 'path': ['org397'], 'locations': [{'line': 1987, 'column': 9}], 'message': \"Could not resolve to an Organization with the login of 'Chatter-Github-Organization'.\"}, {'type': 'NOT_FOUND', 'path': ['org401'], 'locations': [{'line': 2007, 'column': 9}], 'message': \"Could not resolve to an Organization with the login of 'globalrx'.\"}, {'type': 'NOT_FOUND', 'path': ['org426'], 'locations': [{'line': 2132, 'column': 9}], 'message': \"Could not resolve to an Organization with the login of 'unblockedgames789'.\"}, {'type': 'NOT_FOUND', 'path': ['org451'], 'locations': [{'line': 2257, 'column': 9}], 'message': \"Could not resolve to an Organization with the login of 'kreekapp'.\"}]\n",
      "Warning: [{'type': 'NOT_FOUND', 'path': ['org29'], 'locations': [{'line': 147, 'column': 9}], 'message': \"Could not resolve to an Organization with the login of 'My-Rolling-paper'.\"}, {'type': 'NOT_FOUND', 'path': ['org103'], 'locations': [{'line': 517, 'column': 9}], 'message': \"Could not resolve to an Organization with the login of 'SouJunior-Lab'.\"}, {'type': 'NOT_FOUND', 'path': ['org110'], 'locations': [{'line': 552, 'column': 9}], 'message': \"Could not resolve to an Organization with the login of 'nomaInc'.\"}, {'type': 'NOT_FOUND', 'path': ['org220'], 'locations': [{'line': 1102, 'column': 9}], 'message': \"Could not resolve to an Organization with the login of 'FRCteam4909'.\"}, {'type': 'NOT_FOUND', 'path': ['org225'], 'locations': [{'line': 1127, 'column': 9}], 'message': \"Could not resolve to an Organization with the login of 'engsoft-ufcg-22-2'.\"}, {'type': 'NOT_FOUND', 'path': ['org258'], 'locations': [{'line': 1292, 'column': 9}], 'message': \"Could not resolve to an Organization with the login of 'CUBTeamRocket'.\"}, {'type': 'NOT_FOUND', 'path': ['org318'], 'locations': [{'line': 1592, 'column': 9}], 'message': \"Could not resolve to an Organization with the login of 'marcatojs'.\"}, {'type': 'NOT_FOUND', 'path': ['org471'], 'locations': [{'line': 2357, 'column': 9}], 'message': \"Could not resolve to an Organization with the login of 'Neuberger-Shlomo'.\"}, {'type': 'NOT_FOUND', 'path': ['org495'], 'locations': [{'line': 2477, 'column': 9}], 'message': \"Could not resolve to an Organization with the login of 'mershjs'.\"}]\n",
      "Warning: [{'type': 'NOT_FOUND', 'path': ['org88'], 'locations': [{'line': 442, 'column': 9}], 'message': \"Could not resolve to an Organization with the login of 'The-British-50'.\"}, {'type': 'NOT_FOUND', 'path': ['org105'], 'locations': [{'line': 527, 'column': 9}], 'message': \"Could not resolve to an Organization with the login of 'NovelCraft'.\"}]\n"
     ]
    }
   ],
   "source": [
    "## try 3\n",
    "import aiohttp\n",
    "import asyncio\n",
    "import pandas as pd\n",
    "\n",
    "unique_orgs = pd.Series(df['org'].dropna().apply(lambda x: x['login'])).unique()\n",
    "\n",
    "# Batch size\n",
    "BATCH_SIZE = 500\n",
    "\n",
    "def construct_query(org_logins_batch):\n",
    "    return '{' + ' '.join(\n",
    "        f'''\n",
    "        org{index}: organization(login: \"{org_login}\") {{\n",
    "            login\n",
    "            description\n",
    "        }}\n",
    "        ''' for index, org_login in enumerate(org_logins_batch)\n",
    "    ) + '}'\n",
    "\n",
    "async def fetch_data(query, session):\n",
    "    headers = {\n",
    "        'Authorization': f'bearer {github_token}',\n",
    "        'Content-Type': 'application/json'\n",
    "    }\n",
    "    async with session.post('https://api.github.com/graphql', json={'query': query}, headers=headers) as response:\n",
    "        response_json = await response.json()\n",
    "        if 'errors' in response_json:\n",
    "            #print(f\"Warning: {response_json['errors']}\")\n",
    "        return response_json.get('data', {})\n",
    "\n",
    "async def fetch_org_data(org_logins_batch, session):\n",
    "    query = construct_query(org_logins_batch)\n",
    "    return await fetch_data(query, session)\n",
    "\n",
    "async def main():\n",
    "    data = []\n",
    "\n",
    "    async with aiohttp.ClientSession() as session:\n",
    "        for i in range(0, len(unique_orgs), BATCH_SIZE):\n",
    "            org_logins_batch = unique_orgs[i:i + BATCH_SIZE]\n",
    "            batch_data = await fetch_org_data(org_logins_batch, session)\n",
    "            for org_data in batch_data.values():\n",
    "                if org_data:\n",
    "                    data.append([org_data['login'], org_data['description']])\n",
    "            \n",
    "    df_orgs = pd.DataFrame(data, columns=['login', 'description'])\n",
    "    return df_orgs  # return DataFrame\n",
    "\n",
    "# Run the event loop and assign the result to a variable\n",
    "df_orgs = asyncio.run(main())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "9b95dfe1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>login</th>\n",
       "      <th>description</th>\n",
       "      <th>language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>stdlib-js</td>\n",
       "      <td>Standard library for JavaScript.</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Lombiq</td>\n",
       "      <td>A software and services company focusing on we...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CollaboraOnline</td>\n",
       "      <td>Home of Collabora Online, the cloud-based offi...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>nextcloud</td>\n",
       "      <td> A safe home for all your data  community...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tf2pickup-org</td>\n",
       "      <td>Team Fortress 2 pick-up games for everyone</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             login                                        description language\n",
       "0        stdlib-js                   Standard library for JavaScript.       en\n",
       "1           Lombiq  A software and services company focusing on we...       en\n",
       "2  CollaboraOnline  Home of Collabora Online, the cloud-based offi...       en\n",
       "3        nextcloud   A safe home for all your data  community...       en\n",
       "4    tf2pickup-org         Team Fortress 2 pick-up games for everyone       en"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_orgs.to_csv('data/df_orgs.csv', index=False)\n",
    "\n",
    "df_orgs.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b1ccdb6",
   "metadata": {},
   "source": [
    "### Lingua\n",
    "https://github.com/pemistahl/lingua-py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "d5d276ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>login</th>\n",
       "      <th>description</th>\n",
       "      <th>language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>390</th>\n",
       "      <td>xDroidOSS-Pixel</td>\n",
       "      <td>Credit :  xdroidOSS (mnmlist)</td>\n",
       "      <td>ITALIAN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>403</th>\n",
       "      <td>polito-WA1-AW1-2023</td>\n",
       "      <td>Courses at Politecnico di Torino - Academic Ye...</td>\n",
       "      <td>ITALIAN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>703</th>\n",
       "      <td>MOVIECORD</td>\n",
       "      <td> Movie | Film Festival | OTT</td>\n",
       "      <td>ITALIAN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1043</th>\n",
       "      <td>realme-mt6781-dev</td>\n",
       "      <td>AOSP Sources For Realme 8i/Narzo 50</td>\n",
       "      <td>ITALIAN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1054</th>\n",
       "      <td>ipfs</td>\n",
       "      <td>A peer-to-peer hypermedia protocol</td>\n",
       "      <td>ITALIAN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    login                                        description  \\\n",
       "390       xDroidOSS-Pixel                      Credit :  xdroidOSS (mnmlist)   \n",
       "403   polito-WA1-AW1-2023  Courses at Politecnico di Torino - Academic Ye...   \n",
       "703             MOVIECORD                       Movie | Film Festival | OTT   \n",
       "1043    realme-mt6781-dev                AOSP Sources For Realme 8i/Narzo 50   \n",
       "1054                 ipfs                 A peer-to-peer hypermedia protocol   \n",
       "\n",
       "     language  \n",
       "390   ITALIAN  \n",
       "403   ITALIAN  \n",
       "703   ITALIAN  \n",
       "1043  ITALIAN  \n",
       "1054  ITALIAN  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from lingua import Language, LanguageDetectorBuilder\n",
    "import pandas as pd\n",
    "\n",
    "df_lingua = df_orgs.copy()\n",
    "\n",
    "# Available languages\n",
    "languages = [Language.ENGLISH, Language.FRENCH, Language.GERMAN, Language.SPANISH, Language.ITALIAN]\n",
    "\n",
    "# Build the language detector\n",
    "detector = LanguageDetectorBuilder.from_languages(*languages).build()\n",
    "\n",
    "# Function to detect language\n",
    "def detect_language(text):\n",
    "    try:\n",
    "        return detector.detect_language_of(text).name\n",
    "    except:\n",
    "        return \"unknown\"\n",
    "\n",
    "# Apply the function to the 'description' column and store the result in a new column 'language'\n",
    "df_lingua['language'] = df_lingua['description'].apply(detect_language)\n",
    "\n",
    "# Display the DataFrame\n",
    "df_lingua[df_lingua[\"language\"]==\"ITALIAN\"].head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc165dec",
   "metadata": {},
   "source": [
    "### Langdetect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "28c45ead",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>login</th>\n",
       "      <th>description</th>\n",
       "      <th>language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>241</th>\n",
       "      <td>TYPO3-Documentation</td>\n",
       "      <td>Official TYPO3 Documentation</td>\n",
       "      <td>it</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>378</th>\n",
       "      <td>project-violet</td>\n",
       "      <td>Violation Violet</td>\n",
       "      <td>it</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>616</th>\n",
       "      <td>PositiveSumNet</td>\n",
       "      <td>non-commercial use</td>\n",
       "      <td>it</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>703</th>\n",
       "      <td>MOVIECORD</td>\n",
       "      <td> Movie | Film Festival | OTT</td>\n",
       "      <td>it</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>715</th>\n",
       "      <td>nomic-ai</td>\n",
       "      <td>democratizing access to powerful artificial in...</td>\n",
       "      <td>it</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1378</th>\n",
       "      <td>RR0</td>\n",
       "      <td>UFO data since 1998</td>\n",
       "      <td>it</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1455</th>\n",
       "      <td>CreaMate-Consulting</td>\n",
       "      <td>smart digital solutions</td>\n",
       "      <td>it</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1662</th>\n",
       "      <td>JuliaPlots</td>\n",
       "      <td>Data visualization in Julia</td>\n",
       "      <td>it</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1833</th>\n",
       "      <td>theia-ailabs</td>\n",
       "      <td>AI Voice Assistant</td>\n",
       "      <td>it</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1958</th>\n",
       "      <td>panoramicdata</td>\n",
       "      <td>Panoramic Data Limited</td>\n",
       "      <td>it</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2144</th>\n",
       "      <td>dripnillbyteskidrip</td>\n",
       "      <td>Official somalia devs</td>\n",
       "      <td>it</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2253</th>\n",
       "      <td>AppliedDataSciencePartners</td>\n",
       "      <td>A data science consultancy, delivering innovat...</td>\n",
       "      <td>it</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2966</th>\n",
       "      <td>bokeh</td>\n",
       "      <td>Interactive Data Visualization</td>\n",
       "      <td>it</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3025</th>\n",
       "      <td>EazyAutodelete</td>\n",
       "      <td>EazyAutodelete - A Discord Bot to automaticall...</td>\n",
       "      <td>it</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3217</th>\n",
       "      <td>doclingjs</td>\n",
       "      <td>Participatory design for language documentation</td>\n",
       "      <td>it</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3850</th>\n",
       "      <td>sangria-graphql</td>\n",
       "      <td>Sangria - Scala GraphQL implementation</td>\n",
       "      <td>it</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4024</th>\n",
       "      <td>useVenice</td>\n",
       "      <td>Frictionless financial data.</td>\n",
       "      <td>it</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4324</th>\n",
       "      <td>CMU-HKN</td>\n",
       "      <td>Eta Kappa Nu at Carnegie Mellon</td>\n",
       "      <td>it</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4559</th>\n",
       "      <td>rhasspy</td>\n",
       "      <td>Offline voice assistant</td>\n",
       "      <td>it</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4748</th>\n",
       "      <td>FNNDSC</td>\n",
       "      <td>Fetal-Neonatal Neuroimaging Developmental Scie...</td>\n",
       "      <td>it</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5285</th>\n",
       "      <td>Thorium-Sim</td>\n",
       "      <td>Next-generation space simulator controls</td>\n",
       "      <td>it</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5501</th>\n",
       "      <td>BSData</td>\n",
       "      <td>Home for BattleScribe datafiles (catalogues)</td>\n",
       "      <td>it</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5614</th>\n",
       "      <td>TdP-2023</td>\n",
       "      <td>Pagina ufficiale del corso di Tecniche di Prog...</td>\n",
       "      <td>it</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5646</th>\n",
       "      <td>mozilla-mobile</td>\n",
       "      <td>Mozilla Mobile Applications</td>\n",
       "      <td>it</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6279</th>\n",
       "      <td>piql</td>\n",
       "      <td>Reshaping digital preservation</td>\n",
       "      <td>it</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6409</th>\n",
       "      <td>Chaox-Community</td>\n",
       "      <td>We still prevail</td>\n",
       "      <td>it</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6543</th>\n",
       "      <td>PizzaDAO</td>\n",
       "      <td>pizza shud b free</td>\n",
       "      <td>it</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6705</th>\n",
       "      <td>vueComponent</td>\n",
       "      <td>vue component</td>\n",
       "      <td>it</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6840</th>\n",
       "      <td>ettle</td>\n",
       "      <td>Positive Intent</td>\n",
       "      <td>it</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6953</th>\n",
       "      <td>toml-f</td>\n",
       "      <td>A TOML parser implementation for data serializ...</td>\n",
       "      <td>it</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           login  \\\n",
       "241          TYPO3-Documentation   \n",
       "378               project-violet   \n",
       "616               PositiveSumNet   \n",
       "703                    MOVIECORD   \n",
       "715                     nomic-ai   \n",
       "1378                         RR0   \n",
       "1455         CreaMate-Consulting   \n",
       "1662                  JuliaPlots   \n",
       "1833                theia-ailabs   \n",
       "1958               panoramicdata   \n",
       "2144         dripnillbyteskidrip   \n",
       "2253  AppliedDataSciencePartners   \n",
       "2966                       bokeh   \n",
       "3025              EazyAutodelete   \n",
       "3217                   doclingjs   \n",
       "3850             sangria-graphql   \n",
       "4024                   useVenice   \n",
       "4324                     CMU-HKN   \n",
       "4559                     rhasspy   \n",
       "4748                      FNNDSC   \n",
       "5285                 Thorium-Sim   \n",
       "5501                      BSData   \n",
       "5614                    TdP-2023   \n",
       "5646              mozilla-mobile   \n",
       "6279                        piql   \n",
       "6409             Chaox-Community   \n",
       "6543                    PizzaDAO   \n",
       "6705                vueComponent   \n",
       "6840                       ettle   \n",
       "6953                      toml-f   \n",
       "\n",
       "                                            description language  \n",
       "241                        Official TYPO3 Documentation       it  \n",
       "378                                    Violation Violet       it  \n",
       "616                                  non-commercial use       it  \n",
       "703                        Movie | Film Festival | OTT       it  \n",
       "715   democratizing access to powerful artificial in...       it  \n",
       "1378                                UFO data since 1998       it  \n",
       "1455                            smart digital solutions       it  \n",
       "1662                        Data visualization in Julia       it  \n",
       "1833                                 AI Voice Assistant       it  \n",
       "1958                             Panoramic Data Limited       it  \n",
       "2144                              Official somalia devs       it  \n",
       "2253  A data science consultancy, delivering innovat...       it  \n",
       "2966                    Interactive Data Visualization        it  \n",
       "3025  EazyAutodelete - A Discord Bot to automaticall...       it  \n",
       "3217    Participatory design for language documentation       it  \n",
       "3850            Sangria - Scala GraphQL implementation        it  \n",
       "4024                       Frictionless financial data.       it  \n",
       "4324                    Eta Kappa Nu at Carnegie Mellon       it  \n",
       "4559                            Offline voice assistant       it  \n",
       "4748  Fetal-Neonatal Neuroimaging Developmental Scie...       it  \n",
       "5285           Next-generation space simulator controls       it  \n",
       "5501       Home for BattleScribe datafiles (catalogues)       it  \n",
       "5614  Pagina ufficiale del corso di Tecniche di Prog...       it  \n",
       "5646                        Mozilla Mobile Applications       it  \n",
       "6279                     Reshaping digital preservation       it  \n",
       "6409                                   We still prevail       it  \n",
       "6543                                  pizza shud b free       it  \n",
       "6705                                      vue component       it  \n",
       "6840                                    Positive Intent       it  \n",
       "6953  A TOML parser implementation for data serializ...       it  "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langdetect import detect\n",
    "\n",
    "df_langdetect = df_orgs.copy()\n",
    "\n",
    "# Function to detect language\n",
    "def detect_language(text):\n",
    "    try:\n",
    "        return detect(text)\n",
    "    except:\n",
    "        return \"unknown\"\n",
    "\n",
    "# Apply the function to the 'description' column and store the result in a new column 'language'\n",
    "df_langdetect['language'] = df_langdetect['description'].apply(detect_language)\n",
    "\n",
    "# Display the DataFrame\n",
    "df_langdetect[df_langdetect[\"language\"] == \"it\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fabb262",
   "metadata": {},
   "source": [
    "#### Spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "f30ab6d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      login  \\\n",
      "241     TYPO3-Documentation   \n",
      "296                  juspay   \n",
      "378          project-violet   \n",
      "616          PositiveSumNet   \n",
      "715                nomic-ai   \n",
      "1378                    RR0   \n",
      "1455    CreaMate-Consulting   \n",
      "1662             JuliaPlots   \n",
      "1833           theia-ailabs   \n",
      "1958          panoramicdata   \n",
      "2144    dripnillbyteskidrip   \n",
      "2966                  bokeh   \n",
      "3025         EazyAutodelete   \n",
      "3355  softeng2223-inf-uniba   \n",
      "3850        sangria-graphql   \n",
      "4024              useVenice   \n",
      "4324                CMU-HKN   \n",
      "4559                rhasspy   \n",
      "4748                 FNNDSC   \n",
      "5614               TdP-2023   \n",
      "5646         mozilla-mobile   \n",
      "6279                   piql   \n",
      "6409        Chaox-Community   \n",
      "6468        DevStyleDigital   \n",
      "6543               PizzaDAO   \n",
      "6705           vueComponent   \n",
      "6840                  ettle   \n",
      "6953                 toml-f   \n",
      "\n",
      "                                            description language  \n",
      "241                        Official TYPO3 Documentation       it  \n",
      "296    Design to simplify. Revolutionizing digital p...       it  \n",
      "378                                    Violation Violet       it  \n",
      "616                                  non-commercial use       it  \n",
      "715   democratizing access to powerful artificial in...       it  \n",
      "1378                                UFO data since 1998       it  \n",
      "1455                            smart digital solutions       it  \n",
      "1662                        Data visualization in Julia       it  \n",
      "1833                                 AI Voice Assistant       it  \n",
      "1958                             Panoramic Data Limited       it  \n",
      "2144                              Official somalia devs       it  \n",
      "2966                    Interactive Data Visualization        it  \n",
      "3025  EazyAutodelete - A Discord Bot to automaticall...       it  \n",
      "3355  Ingegneria del Software a.a. 2022/2023, CdL In...       it  \n",
      "3850            Sangria - Scala GraphQL implementation        it  \n",
      "4024                       Frictionless financial data.       it  \n",
      "4324                    Eta Kappa Nu at Carnegie Mellon       it  \n",
      "4559                            Offline voice assistant       it  \n",
      "4748  Fetal-Neonatal Neuroimaging Developmental Scie...       it  \n",
      "5614  Pagina ufficiale del corso di Tecniche di Prog...       it  \n",
      "5646                        Mozilla Mobile Applications       it  \n",
      "6279                     Reshaping digital preservation       it  \n",
      "6409                                   We still prevail       it  \n",
      "6468                       Desenvolvimento Web e Mobile       it  \n",
      "6543                                  pizza shud b free       it  \n",
      "6705                                      vue component       it  \n",
      "6840                                    Positive Intent       it  \n",
      "6953  A TOML parser implementation for data serializ...       it  \n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "from spacy.language import Language\n",
    "from spacy_langdetect import LanguageDetector\n",
    "import pandas as pd\n",
    "\n",
    "# Load English tokenizer, tagger, parser, NER and word vectors\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "@Language.factory(\"language_detector\")\n",
    "def create_language_detector(nlp, name):\n",
    "    return LanguageDetector()\n",
    "\n",
    "# Add the language detector to the pipeline\n",
    "nlp.add_pipe('language_detector', last=True)\n",
    "\n",
    "# A copy of your DataFrame to work with\n",
    "df_spacy = df_orgs.copy()\n",
    "\n",
    "# Function to detect language using spaCy\n",
    "def detect_language(text):\n",
    "    try:\n",
    "        doc = nlp(text)\n",
    "        return doc._.language['language']\n",
    "    except:\n",
    "        return \"unknown\"\n",
    "\n",
    "# Apply the function to the 'description' column and store the result in a new column 'language'\n",
    "df_spacy['language'] = df_spacy['description'].apply(detect_language)\n",
    "\n",
    "# Display the DataFrame with Italian descriptions\n",
    "print(df_spacy[df_spacy[\"language\"] == \"it\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "3ba7faf4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>login</th>\n",
       "      <th>description</th>\n",
       "      <th>language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>241</th>\n",
       "      <td>TYPO3-Documentation</td>\n",
       "      <td>Official TYPO3 Documentation</td>\n",
       "      <td>it</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>juspay</td>\n",
       "      <td>Design to simplify. Revolutionizing digital p...</td>\n",
       "      <td>it</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>378</th>\n",
       "      <td>project-violet</td>\n",
       "      <td>Violation Violet</td>\n",
       "      <td>it</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>616</th>\n",
       "      <td>PositiveSumNet</td>\n",
       "      <td>non-commercial use</td>\n",
       "      <td>it</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>715</th>\n",
       "      <td>nomic-ai</td>\n",
       "      <td>democratizing access to powerful artificial in...</td>\n",
       "      <td>it</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   login                                        description  \\\n",
       "241  TYPO3-Documentation                       Official TYPO3 Documentation   \n",
       "296               juspay   Design to simplify. Revolutionizing digital p...   \n",
       "378       project-violet                                   Violation Violet   \n",
       "616       PositiveSumNet                                 non-commercial use   \n",
       "715             nomic-ai  democratizing access to powerful artificial in...   \n",
       "\n",
       "    language  \n",
       "241       it  \n",
       "296       it  \n",
       "378       it  \n",
       "616       it  \n",
       "715       it  "
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_spacy[df_spacy[\"language\"] == \"it\"].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "367cf6ca",
   "metadata": {},
   "source": [
    "## 7. Italian Open Source Licences\n",
    "Problem is, that the authors are italian but not living in Italy!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7fa598b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2Ami',\n",
       " 'Apivault',\n",
       " 'Arduino',\n",
       " 'Arduino Desk Weatherstation',\n",
       " 'Argon',\n",
       " 'Autocannon',\n",
       " 'Awesome Italia Open Source',\n",
       " 'Bootstrap Italia',\n",
       " 'Breathly',\n",
       " 'Cache Candidate']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "import re\n",
    "import os\n",
    "\n",
    "def get_and_process_github_readme(url, filename, token):\n",
    "    \"\"\"\n",
    "    Download the README.md from GitHub, save it, extract and return the names of repositories.\n",
    "    \n",
    "    Parameters:\n",
    "        url (str): The URL to the raw README.md on GitHub.\n",
    "        filename (str): The name to save the README.md as.\n",
    "        token (str): Your GitHub API token.\n",
    "        \n",
    "    Returns:\n",
    "        list: Extracted repository names.\n",
    "    \"\"\"\n",
    "    headers = {\n",
    "        \"Authorization\": f\"token {token}\",\n",
    "        \"Accept\": \"application/vnd.github.v3.raw\"\n",
    "    }\n",
    "    \n",
    "    # Step 1: Download the README.md from GitHub\n",
    "    response = requests.get(url, headers=headers)\n",
    "    \n",
    "    # Ensure the request was successful\n",
    "    if response.status_code == 200:\n",
    "        readme_content = response.text\n",
    "        \n",
    "        # Step 2: Process the saved file to extract repository names\n",
    "        name_pattern = re.compile(r'\\|\\s*(?:\\[(?P<link_name>.+?)\\]\\(.+?\\)|(?P<plain_name>[^\\|\\[\\]]+))\\s*\\|')\n",
    "        names = []\n",
    "        for line in readme_content.split('\\n'):\n",
    "            match = name_pattern.search(line)\n",
    "            if match:\n",
    "                name = (match.group('link_name') or match.group('plain_name')).strip()\n",
    "                if name and name.lower() not in [\"name\", \"----\", \"stack\", \"description\"]:\n",
    "                    names.append(name)\n",
    "        return names\n",
    "    else:\n",
    "        raise ConnectionError(f\"Failed to fetch README.md, status code: {response.status_code}\")\n",
    "\n",
    "# URL to the raw README.md on GitHub\n",
    "readme_url = \"https://github.com/italia-opensource/awesome-italia-opensource/raw/main/awesome/opensource/README.md\"\n",
    "\n",
    "# Filename to save the README.md as\n",
    "save_filename = \"github_readme.md\"\n",
    "\n",
    "# Execute the function and display the first 10 repository names\n",
    "Italian_OS_projects = get_and_process_github_readme(readme_url, save_filename, github_token)[1:]\n",
    "Italian_OS_projects[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9e6115e",
   "metadata": {},
   "source": [
    "## Extras"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e45a951",
   "metadata": {},
   "source": [
    "### downloading data for multiple days/hours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b87db6c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import gzip\n",
    "import pandas as pd\n",
    "import logging\n",
    "from typing import List, Union\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "BASE_URL = \"https://data.gharchive.org\"\n",
    "\n",
    "def ensure_directory_exists(dir_name: str) -> None:\n",
    "    \"\"\"Ensure the specified directory exists.\"\"\"\n",
    "    if not os.path.exists(dir_name):\n",
    "        os.makedirs(dir_name)\n",
    "\n",
    "def download_file(url: str, file_path: str) -> None:\n",
    "    \"\"\"Download file and save it to the specified path.\"\"\"\n",
    "    try:\n",
    "        response = requests.get(url, stream=True)\n",
    "        if response.status_code == 200:\n",
    "            with open(file_path, 'wb') as f:\n",
    "                for chunk in response.iter_content(chunk_size=128):\n",
    "                    f.write(chunk)\n",
    "        else:\n",
    "            logging.warning(f\"File not found: {url}\")\n",
    "    except requests.RequestException as e:\n",
    "        logging.error(f\"Failed to fetch {url}: {str(e)}\")\n",
    "\n",
    "def load_or_fetch_data(file_path: str, url: str) -> Union[pd.DataFrame, None]:\n",
    "    \"\"\"Load data from file or fetch from URL if not exists.\"\"\"\n",
    "    if os.path.exists(file_path):\n",
    "        logging.info(f\"File {file_path} already exists. Loading data.\")\n",
    "        with gzip.open(file_path, 'rt', encoding='utf-8') as gz:\n",
    "            return pd.read_json(gz, lines=True)\n",
    "    else:\n",
    "        logging.info(f\"File {file_path} not exists. Downloading from {url}\")\n",
    "        download_file(url, file_path)\n",
    "        if os.path.exists(file_path):\n",
    "            with gzip.open(file_path, 'rt', encoding='utf-8') as gz:\n",
    "                return pd.read_json(gz, lines=True)\n",
    "    return None\n",
    "\n",
    "def download_gh_archive(start_day: int, end_day: int, \n",
    "                        start_hour: int=0, end_hour: int=23,\n",
    "                        base_url: str=BASE_URL, data_dir: str='data') -> pd.DataFrame:\n",
    "    \"\"\"Download GitHub archive data for specified days and hours.\"\"\"\n",
    "    dfs = []\n",
    "    ensure_directory_exists(data_dir)\n",
    "    \n",
    "    for day in range(start_day, end_day + 1):\n",
    "        for hour in range(start_hour, end_hour + 1):\n",
    "            filename = f\"2023-04-{day:02d}-{hour}.json.gz\"\n",
    "            url = f\"{base_url}/{filename}\"\n",
    "            file_path = os.path.join(data_dir, filename)\n",
    "            \n",
    "            df = load_or_fetch_data(file_path, url)\n",
    "            if df is not None:\n",
    "                dfs.append(df)\n",
    "\n",
    "    return pd.concat(dfs, ignore_index=True) if dfs else pd.DataFrame()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15c8a747",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Record the start time\n",
    "start_time = time.time()\n",
    "#Define the start and end date-time\n",
    "start_date_time = \"2023-04-01 10\"  # Format: \"YYYY-MM-DD HH\"\n",
    "end_date_time = \"2023-04-01 12\"    # Format: \"YYYY-MM-DD HH\"\n",
    "# Extract day and hour from the date-time strings\n",
    "start_day = int(start_date_time.split(\"-\")[2].split()[0])\n",
    "start_hour = int(start_date_time.split()[1])\n",
    "end_day = int(end_date_time.split(\"-\")[2].split()[0])\n",
    "end_hour = int(end_date_time.split()[1])\n",
    "\n",
    "# Download data for the specified time frame\n",
    "df_big = download_gh_archive(start_day, end_day, start_hour, end_hour)\n",
    "\n",
    "# Record the end time and calculate the elapsed time\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "\n",
    "print(f\"Data from {start_date_time} to {end_date_time} loaded into DataFrame!\")\n",
    "print(f\"Time taken: {elapsed_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "206a9485",
   "metadata": {},
   "source": [
    "### Getting rid of Github Bot commits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56206ce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df = df[~df['actor'].apply(lambda x: x.get('login').endswith('[bot]'))]\n",
    "filtered_df.reset_index(drop=True, inplace=True)\n",
    "filtered_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5a81a51",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py:light"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
