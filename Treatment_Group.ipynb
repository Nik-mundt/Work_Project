{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ac0ecf7f",
   "metadata": {},
   "source": [
    "# Finding the Treatment Group"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d912856a",
   "metadata": {},
   "source": [
    "Pre requisites\n",
    "1. config.py in the config folder in the following format\n",
    "ACCESS_TOKEN = \"ghp_xxxx\"\n",
    "GITHUB_TOKEN = \"github_pat_xxxxx\"\n",
    "2. data folder where all data will be stored"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e3ecae2",
   "metadata": {},
   "source": [
    "#### Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1589b178-0df4-46f7-843a-bcbc09de9042",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "!pip install langdetect\n",
    "!pip install fuzzywuzzy\n",
    "!pip install python-Levenshtein\n",
    "!pip install graphqlclient\n",
    "!pip install lingua-language-detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47f5c8cd-de5f-4517-9a9d-2c520904ba6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import os\n",
    "import sys\n",
    "from config import config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7ce46e86",
   "metadata": {},
   "outputs": [],
   "source": [
    "access_token = config.ACCESS_TOKEN\n",
    "github_token = config.GITHUB_TOKEN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10b964f3",
   "metadata": {},
   "source": [
    "#### Download the example file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1fad7092",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File downloaded successfully and saved to data/2023-04-01-15.json.gz\n"
     ]
    }
   ],
   "source": [
    "# Ensure the 'data' folder exists\n",
    "if not os.path.exists('data'):\n",
    "    os.makedirs('data')\n",
    "\n",
    "url = 'https://data.gharchive.org/2023-04-01-15.json.gz'\n",
    "file_path = os.path.join('data', '2023-04-01-15.json.gz')\n",
    "\n",
    "# Check if the file already exists\n",
    "if os.path.exists(file_path):\n",
    "    print(f\"The file already exists at {file_path}. No need to download.\")\n",
    "else:\n",
    "    response = requests.get(url, stream=True)\n",
    "    # Check if the request was successful (HTTP Status Code 200)\n",
    "    if response.status_code == 200:\n",
    "        # Write the file\n",
    "        with open(file_path, 'wb') as file:\n",
    "            for chunk in response.iter_content(chunk_size=128):\n",
    "                file.write(chunk)\n",
    "        print(f\"File downloaded successfully and saved to {file_path}\")\n",
    "    else:\n",
    "        print(\"Failed to fetch the file\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f25880f0",
   "metadata": {},
   "source": [
    "#### read it in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8fb9ff13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>type</th>\n",
       "      <th>actor</th>\n",
       "      <th>repo</th>\n",
       "      <th>payload</th>\n",
       "      <th>public</th>\n",
       "      <th>created_at</th>\n",
       "      <th>org</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>28137501092</td>\n",
       "      <td>PushEvent</td>\n",
       "      <td>{'id': 41898282, 'login': 'github-actions[bot]...</td>\n",
       "      <td>{'id': 568277185, 'name': 'stdlib-js/strided-b...</td>\n",
       "      <td>{'repository_id': 568277185, 'push_id': 131547...</td>\n",
       "      <td>True</td>\n",
       "      <td>2023-04-01 15:00:00+00:00</td>\n",
       "      <td>{'id': 17805691, 'login': 'stdlib-js', 'gravat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>28137501094</td>\n",
       "      <td>CreateEvent</td>\n",
       "      <td>{'id': 115239975, 'login': 'ishuduwal', 'displ...</td>\n",
       "      <td>{'id': 622248753, 'name': 'ishuduwal/personal-...</td>\n",
       "      <td>{'ref': 'main', 'ref_type': 'branch', 'master_...</td>\n",
       "      <td>True</td>\n",
       "      <td>2023-04-01 15:00:00+00:00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28137501097</td>\n",
       "      <td>CreateEvent</td>\n",
       "      <td>{'id': 50960481, 'login': 'bxbao87', 'display_...</td>\n",
       "      <td>{'id': 622248756, 'name': 'bxbao87/bloglist', ...</td>\n",
       "      <td>{'ref': 'main', 'ref_type': 'branch', 'master_...</td>\n",
       "      <td>True</td>\n",
       "      <td>2023-04-01 15:00:00+00:00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>28137501098</td>\n",
       "      <td>PushEvent</td>\n",
       "      <td>{'id': 52915358, 'login': 'alwaz-shahid', 'dis...</td>\n",
       "      <td>{'id': 622201481, 'name': 'alwaz-shahid/extens...</td>\n",
       "      <td>{'repository_id': 622201481, 'push_id': 131547...</td>\n",
       "      <td>True</td>\n",
       "      <td>2023-04-01 15:00:00+00:00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28137501099</td>\n",
       "      <td>CreateEvent</td>\n",
       "      <td>{'id': 101326737, 'login': 'HOVADOVOLE', 'disp...</td>\n",
       "      <td>{'id': 622248605, 'name': 'HOVADOVOLE/Serial-P...</td>\n",
       "      <td>{'ref': 'main', 'ref_type': 'branch', 'master_...</td>\n",
       "      <td>True</td>\n",
       "      <td>2023-04-01 15:00:00+00:00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            id         type  \\\n",
       "0  28137501092    PushEvent   \n",
       "1  28137501094  CreateEvent   \n",
       "2  28137501097  CreateEvent   \n",
       "3  28137501098    PushEvent   \n",
       "4  28137501099  CreateEvent   \n",
       "\n",
       "                                               actor  \\\n",
       "0  {'id': 41898282, 'login': 'github-actions[bot]...   \n",
       "1  {'id': 115239975, 'login': 'ishuduwal', 'displ...   \n",
       "2  {'id': 50960481, 'login': 'bxbao87', 'display_...   \n",
       "3  {'id': 52915358, 'login': 'alwaz-shahid', 'dis...   \n",
       "4  {'id': 101326737, 'login': 'HOVADOVOLE', 'disp...   \n",
       "\n",
       "                                                repo  \\\n",
       "0  {'id': 568277185, 'name': 'stdlib-js/strided-b...   \n",
       "1  {'id': 622248753, 'name': 'ishuduwal/personal-...   \n",
       "2  {'id': 622248756, 'name': 'bxbao87/bloglist', ...   \n",
       "3  {'id': 622201481, 'name': 'alwaz-shahid/extens...   \n",
       "4  {'id': 622248605, 'name': 'HOVADOVOLE/Serial-P...   \n",
       "\n",
       "                                             payload  public  \\\n",
       "0  {'repository_id': 568277185, 'push_id': 131547...    True   \n",
       "1  {'ref': 'main', 'ref_type': 'branch', 'master_...    True   \n",
       "2  {'ref': 'main', 'ref_type': 'branch', 'master_...    True   \n",
       "3  {'repository_id': 622201481, 'push_id': 131547...    True   \n",
       "4  {'ref': 'main', 'ref_type': 'branch', 'master_...    True   \n",
       "\n",
       "                 created_at                                                org  \n",
       "0 2023-04-01 15:00:00+00:00  {'id': 17805691, 'login': 'stdlib-js', 'gravat...  \n",
       "1 2023-04-01 15:00:00+00:00                                                NaN  \n",
       "2 2023-04-01 15:00:00+00:00                                                NaN  \n",
       "3 2023-04-01 15:00:00+00:00                                                NaN  \n",
       "4 2023-04-01 15:00:00+00:00                                                NaN  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_json(\"data/2023-04-01-15.json.gz\", lines=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b77a69d",
   "metadata": {},
   "source": [
    "## 1. Identifying user location based on their GitHub profiles\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fed77c0",
   "metadata": {},
   "source": [
    "####  GraphQL for batch requests to fetch data for multiple users in one request instead of making a request for each user and constantly hitting the rate limit for the REST API\n",
    "1. GraphQL Test: Creates data subset, constructs/executes GraphQL query for user locations\n",
    "2. Italian Identification: Uses Italian keywords to filter and display Italian users\n",
    "- subset of 500 Users >> 3 Italians identified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aa81dd6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>type</th>\n",
       "      <th>actor</th>\n",
       "      <th>repo</th>\n",
       "      <th>payload</th>\n",
       "      <th>public</th>\n",
       "      <th>created_at</th>\n",
       "      <th>org</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>28137501092</td>\n",
       "      <td>PushEvent</td>\n",
       "      <td>{'id': 41898282, 'login': 'github-actions[bot]...</td>\n",
       "      <td>{'id': 568277185, 'name': 'stdlib-js/strided-b...</td>\n",
       "      <td>{'repository_id': 568277185, 'push_id': 131547...</td>\n",
       "      <td>True</td>\n",
       "      <td>2023-04-01 15:00:00+00:00</td>\n",
       "      <td>{'id': 17805691, 'login': 'stdlib-js', 'gravat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>28137501094</td>\n",
       "      <td>CreateEvent</td>\n",
       "      <td>{'id': 115239975, 'login': 'ishuduwal', 'displ...</td>\n",
       "      <td>{'id': 622248753, 'name': 'ishuduwal/personal-...</td>\n",
       "      <td>{'ref': 'main', 'ref_type': 'branch', 'master_...</td>\n",
       "      <td>True</td>\n",
       "      <td>2023-04-01 15:00:00+00:00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28137501097</td>\n",
       "      <td>CreateEvent</td>\n",
       "      <td>{'id': 50960481, 'login': 'bxbao87', 'display_...</td>\n",
       "      <td>{'id': 622248756, 'name': 'bxbao87/bloglist', ...</td>\n",
       "      <td>{'ref': 'main', 'ref_type': 'branch', 'master_...</td>\n",
       "      <td>True</td>\n",
       "      <td>2023-04-01 15:00:00+00:00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>28137501098</td>\n",
       "      <td>PushEvent</td>\n",
       "      <td>{'id': 52915358, 'login': 'alwaz-shahid', 'dis...</td>\n",
       "      <td>{'id': 622201481, 'name': 'alwaz-shahid/extens...</td>\n",
       "      <td>{'repository_id': 622201481, 'push_id': 131547...</td>\n",
       "      <td>True</td>\n",
       "      <td>2023-04-01 15:00:00+00:00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28137501099</td>\n",
       "      <td>CreateEvent</td>\n",
       "      <td>{'id': 101326737, 'login': 'HOVADOVOLE', 'disp...</td>\n",
       "      <td>{'id': 622248605, 'name': 'HOVADOVOLE/Serial-P...</td>\n",
       "      <td>{'ref': 'main', 'ref_type': 'branch', 'master_...</td>\n",
       "      <td>True</td>\n",
       "      <td>2023-04-01 15:00:00+00:00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            id         type  \\\n",
       "0  28137501092    PushEvent   \n",
       "1  28137501094  CreateEvent   \n",
       "2  28137501097  CreateEvent   \n",
       "3  28137501098    PushEvent   \n",
       "4  28137501099  CreateEvent   \n",
       "\n",
       "                                               actor  \\\n",
       "0  {'id': 41898282, 'login': 'github-actions[bot]...   \n",
       "1  {'id': 115239975, 'login': 'ishuduwal', 'displ...   \n",
       "2  {'id': 50960481, 'login': 'bxbao87', 'display_...   \n",
       "3  {'id': 52915358, 'login': 'alwaz-shahid', 'dis...   \n",
       "4  {'id': 101326737, 'login': 'HOVADOVOLE', 'disp...   \n",
       "\n",
       "                                                repo  \\\n",
       "0  {'id': 568277185, 'name': 'stdlib-js/strided-b...   \n",
       "1  {'id': 622248753, 'name': 'ishuduwal/personal-...   \n",
       "2  {'id': 622248756, 'name': 'bxbao87/bloglist', ...   \n",
       "3  {'id': 622201481, 'name': 'alwaz-shahid/extens...   \n",
       "4  {'id': 622248605, 'name': 'HOVADOVOLE/Serial-P...   \n",
       "\n",
       "                                             payload  public  \\\n",
       "0  {'repository_id': 568277185, 'push_id': 131547...    True   \n",
       "1  {'ref': 'main', 'ref_type': 'branch', 'master_...    True   \n",
       "2  {'ref': 'main', 'ref_type': 'branch', 'master_...    True   \n",
       "3  {'repository_id': 622201481, 'push_id': 131547...    True   \n",
       "4  {'ref': 'main', 'ref_type': 'branch', 'master_...    True   \n",
       "\n",
       "                 created_at                                                org  \n",
       "0 2023-04-01 15:00:00+00:00  {'id': 17805691, 'login': 'stdlib-js', 'gravat...  \n",
       "1 2023-04-01 15:00:00+00:00                                                NaN  \n",
       "2 2023-04-01 15:00:00+00:00                                                NaN  \n",
       "3 2023-04-01 15:00:00+00:00                                                NaN  \n",
       "4 2023-04-01 15:00:00+00:00                                                NaN  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def sanitize_for_alias(username):\n",
    "    return ''.join(ch if ch.isalnum() else '_' for ch in username)\n",
    "\n",
    "def construct_query(logins):\n",
    "    query_parts = [\n",
    "        f'''\n",
    "        {sanitize_for_alias(login)}: user(login: \"{login}\") {{\n",
    "            location\n",
    "        }}\n",
    "        ''' for login in logins\n",
    "    ]\n",
    "    return '{' + ''.join(query_parts) + '}'\n",
    "\n",
    "def fetch_data(query, github_token):\n",
    "    headers = {\n",
    "        'Authorization': 'bearer ' + github_token,\n",
    "        'Content-Type': 'application/json'\n",
    "    }\n",
    "    response = requests.post('https://api.github.com/graphql', json={'query': query}, headers=headers)\n",
    "    response_json = response.json()\n",
    "\n",
    "    if 'data' not in response_json:\n",
    "        raise Exception(\"Data key missing from response:\", response_json)\n",
    "    return response_json['data']\n",
    "\n",
    "def update_location(data):\n",
    "    for login, user_data in data.items():\n",
    "        if user_data is None:\n",
    "            print(f\"No data for user: {login}\")\n",
    "            continue\n",
    "        location = user_data.get('location', None)\n",
    "        mask = df['actor'].apply(lambda x: x['login']) == login\n",
    "        df.loc[mask, 'actor'] = df.loc[mask, 'actor'].apply(\n",
    "            lambda x: {**x, 'location': location}\n",
    "        )\n",
    "\n",
    "# Main code execution\n",
    "github_token = os.getenv('GITHUB_TOKEN')  # Assuming the token is stored as an environment variable\n",
    "\n",
    "logins = df['actor'].apply(lambda x: x['login']).tolist()\n",
    "logins = [login for login in logins if not login[0].isdigit()]\n",
    "\n",
    "query = construct_query(logins)\n",
    "data = fetch_data(query, github_token)\n",
    "update_location(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "21512bf3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    {'id': 41898282, 'login': 'github-actions[bot]...\n",
       "1    {'id': 115239975, 'login': 'ishuduwal', 'displ...\n",
       "2    {'id': 50960481, 'login': 'bxbao87', 'display_...\n",
       "3    {'id': 52915358, 'login': 'alwaz-shahid', 'dis...\n",
       "4    {'id': 101326737, 'login': 'HOVADOVOLE', 'disp...\n",
       "Name: actor, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import fuzzywuzzy\n",
    "from fuzzywuzzy import process\n",
    "\n",
    "# List of major cities in Italy and other possible indications of an Italian location\n",
    "italian_keywords = [\n",
    "    \"rome\", \"roma\", \"milan\", \"milano\", \"naples\", \"napoli\", \"turin\", \"torino\", \"palermo\", \n",
    "    \"genoa\", \"genova\", \"bologna\", \"florence\", \"firenze\", \"venice\", \"venezia\", \"verona\", \n",
    "    \"cagliari\", \"parma\", \"ferrara\", \"treviso\", \"padua\", \"padova\", \"trieste\", \"taranto\", \n",
    "    \"brescia\", \"prato\", \"modena\", \"reggio\", \"calabria\", \"emilia\", \"perugia\", \"livorno\", \n",
    "    \"ravenna\", \"foggia\", \"rimini\", \"salerno\", \"sassari\", \"latina\", \"giugliano\", \"tuscany\", \n",
    "    \"toscana\", \"sicily\", \"sicilia\", \"sardinia\", \"sardegna\", \"lombardy\", \"lombardia\", \"piedmont\", \n",
    "    \"piemonte\", \"liguria\", \"calabria\", \"umbria\", \"marche\", \"abruzzo\", \"italy\", \"italia\"\n",
    "]\n",
    "\n",
    "def is_italian_location(location):\n",
    "    if not location:\n",
    "        return False\n",
    "    location = location.lower()\n",
    "    if any(keyword in location for keyword in italian_keywords):\n",
    "        return True\n",
    "    # Using fuzzy matching to account for typos\n",
    "    closest_match, score = process.extractOne(location, italian_keywords)\n",
    "    return score > 80\n",
    "\n",
    "# Filter out rows with Italian locations\n",
    "non_italian_df = subset_df2[~subset_df2['actor'].apply(lambda x: is_italian_location(x.get('location')))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "506aa1bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>login</th>\n",
       "      <th>display_login</th>\n",
       "      <th>gravatar_id</th>\n",
       "      <th>url</th>\n",
       "      <th>avatar_url</th>\n",
       "      <th>location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16925025</td>\n",
       "      <td>maffo102</td>\n",
       "      <td>maffo102</td>\n",
       "      <td></td>\n",
       "      <td>https://api.github.com/users/maffo102</td>\n",
       "      <td>https://avatars.githubusercontent.com/u/16925025?</td>\n",
       "      <td>Italy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30238962</td>\n",
       "      <td>merkleID</td>\n",
       "      <td>merkleID</td>\n",
       "      <td></td>\n",
       "      <td>https://api.github.com/users/merkleID</td>\n",
       "      <td>https://avatars.githubusercontent.com/u/30238962?</td>\n",
       "      <td>milan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>117077787</td>\n",
       "      <td>Nelexiad</td>\n",
       "      <td>Nelexiad</td>\n",
       "      <td></td>\n",
       "      <td>https://api.github.com/users/Nelexiad</td>\n",
       "      <td>https://avatars.githubusercontent.com/u/117077...</td>\n",
       "      <td>Palermo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>99094086</td>\n",
       "      <td>CrisLap</td>\n",
       "      <td>CrisLap</td>\n",
       "      <td></td>\n",
       "      <td>https://api.github.com/users/CrisLap</td>\n",
       "      <td>https://avatars.githubusercontent.com/u/99094086?</td>\n",
       "      <td>Verona, Italy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>84925446</td>\n",
       "      <td>davidetacchini</td>\n",
       "      <td>davidetacchini</td>\n",
       "      <td></td>\n",
       "      <td>https://api.github.com/users/davidetacchini</td>\n",
       "      <td>https://avatars.githubusercontent.com/u/84925446?</td>\n",
       "      <td>Italy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id           login   display_login gravatar_id  \\\n",
       "0   16925025        maffo102        maffo102               \n",
       "1   30238962        merkleID        merkleID               \n",
       "2  117077787        Nelexiad        Nelexiad               \n",
       "3   99094086         CrisLap         CrisLap               \n",
       "4   84925446  davidetacchini  davidetacchini               \n",
       "\n",
       "                                           url  \\\n",
       "0        https://api.github.com/users/maffo102   \n",
       "1        https://api.github.com/users/merkleID   \n",
       "2        https://api.github.com/users/Nelexiad   \n",
       "3         https://api.github.com/users/CrisLap   \n",
       "4  https://api.github.com/users/davidetacchini   \n",
       "\n",
       "                                          avatar_url       location  \n",
       "0  https://avatars.githubusercontent.com/u/16925025?          Italy  \n",
       "1  https://avatars.githubusercontent.com/u/30238962?          milan  \n",
       "2  https://avatars.githubusercontent.com/u/117077...        Palermo  \n",
       "3  https://avatars.githubusercontent.com/u/99094086?  Verona, Italy  \n",
       "4  https://avatars.githubusercontent.com/u/84925446?          Italy  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filter in rows with Italian locations\n",
    "italian_df = subset_df2[subset_df2['actor'].apply(lambda x: is_italian_location(x.get('location')))]\n",
    "\n",
    "# Flatten the 'actor' column from the italian_df\n",
    "flattened_italian_actor_df = pd.json_normalize(italian_df['actor'])\n",
    "\n",
    "# Display the flattened 'actor' column\n",
    "flattened_italian_actor_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3f7c7c3",
   "metadata": {},
   "source": [
    "## Email Analysis\n",
    "I added a limit of 100 \"df['actor'][:100]\"\n",
    "\n",
    "With this limit I didnt find any email :("
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54083b91",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from graphqlclient import GraphQLClient\n",
    "from config import config\n",
    "\n",
    "def get_client():\n",
    "    client = GraphQLClient('https://api.github.com/graphql')\n",
    "    client.inject_token(f'Bearer {github_token}')\n",
    "    return client\n",
    "\n",
    "def execute_query(client, query, variables=None):\n",
    "    try:\n",
    "        result = client.execute(query, variables)\n",
    "        return json.loads(result)\n",
    "    except Exception as e:\n",
    "        print(f\"Error executing query: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "def get_user_email(client, username):\n",
    "    query = \"\"\"\n",
    "    query($username: String!) {\n",
    "      user(login: $username) {\n",
    "        email\n",
    "      }\n",
    "    }\n",
    "    \"\"\"\n",
    "    variables = {\"username\": username}\n",
    "    \n",
    "    response_json = execute_query(client, query, variables)\n",
    "    \n",
    "    if response_json and \"errors\" in response_json:\n",
    "        error_message = response_json.get(\"errors\")[0].get(\"message\")\n",
    "        print(f\"Error querying user {username}: {error_message}\")\n",
    "        return None\n",
    "    \n",
    "    return response_json[\"data\"][\"user\"][\"email\"] if response_json else None\n",
    "\n",
    "# Example usage:\n",
    "if __name__ == \"__main__\":\n",
    "    client = get_client()\n",
    "    emails = []\n",
    "\n",
    "    for row in df['actor'][:100]:\n",
    "        login = row.get('login')\n",
    "        if login:\n",
    "            email = get_user_email(client, login)\n",
    "            if email:\n",
    "                emails.append(email)\n",
    "            else:\n",
    "                print(f\"No email found for user {login}\")\n",
    "\n",
    "    print(emails)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc4f4d41",
   "metadata": {},
   "outputs": [],
   "source": [
    "emails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a93d48da",
   "metadata": {},
   "outputs": [],
   "source": [
    "it_emails = []\n",
    "\n",
    "for email in emails:\n",
    "    if email.endswith(\".ca\"):\n",
    "        it_emails.append(email)\n",
    "\n",
    "print(\"Emails ending with '.it':\")\n",
    "for it_email in it_emails:\n",
    "    print(it_email)\n",
    "\n",
    "count_it_emails = len(it_emails)\n",
    "print(f\"Number of emails ending with '.it': {count_it_emails}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13e72d85",
   "metadata": {},
   "source": [
    "## 6. Analyzing org descriptions\n",
    "Use GraphQL to get more information at once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "088d56c8",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "unique_orgs = pd.Series(df['org'].dropna().apply(lambda x: x['login'])).unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bd63047a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 154 entries, 1465 to 159465\n",
      "Data columns (total 6 columns):\n",
      " #   Column          Non-Null Count  Dtype \n",
      "---  ------          --------------  ----- \n",
      " 0   repository_id   154 non-null    int64 \n",
      " 1   push_id         154 non-null    int64 \n",
      " 2   author_email    154 non-null    object\n",
      " 3   author_name     154 non-null    object\n",
      " 4   commit_message  154 non-null    object\n",
      " 5   commit_sha      154 non-null    object\n",
      "dtypes: int64(2), object(4)\n",
      "memory usage: 8.4+ KB\n"
     ]
    }
   ],
   "source": [
    "# List of unique organization logins obtained from your DataFrame\n",
    "unique_org_list = unique_orgs[100:900]\n",
    "\n",
    "# Setup GraphQL Client\n",
    "client = GraphQLClient('https://api.github.com/graphql')\n",
    "client.inject_token(f'Bearer {github_token}')\n",
    "\n",
    "# Define GraphQL Query\n",
    "query = \"\"\"\n",
    "query($login: String!) {\n",
    "  organization(login: $login) {\n",
    "    login\n",
    "    description\n",
    "  }\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "# List to store data for the new DataFrame\n",
    "data = []\n",
    "\n",
    "# Loop through each unique organization login\n",
    "for org_login in unique_org_list:\n",
    "    try:\n",
    "        # Define variables for the query\n",
    "        variables = {\"login\": org_login}\n",
    "        \n",
    "        # Execute the GraphQL query\n",
    "        result = client.execute(query, variables)\n",
    "        response_json = json.loads(result)\n",
    "        \n",
    "        # Check for errors in the response\n",
    "        if \"errors\" in response_json:\n",
    "            error_message = response_json['errors'][0]['message']\n",
    "            print(f\"Error querying organization {org_login}: {error_message}\")\n",
    "            continue\n",
    "        \n",
    "        # Extract the relevant data\n",
    "        org_data = response_json['data']['organization']\n",
    "        data.append([org_data['login'], org_data['description']])\n",
    "        \n",
    "    except Exception as err:\n",
    "        # Handle potential errors\n",
    "        print(f\"An error occurred for {org_login}: {err}\")\n",
    "\n",
    "# Create DataFrame\n",
    "df_orgs = pd.DataFrame(data, columns=['name', 'description'])\n",
    "\n",
    "# Display the DataFrame\n",
    "print(df_orgs.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b1ccdb6",
   "metadata": {},
   "source": [
    "### Lingua\n",
    "https://github.com/pemistahl/lingua-py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "d5d276ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>login</th>\n",
       "      <th>description</th>\n",
       "      <th>language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>390</th>\n",
       "      <td>xDroidOSS-Pixel</td>\n",
       "      <td>Credit :  xdroidOSS (mnmlist)</td>\n",
       "      <td>ITALIAN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>403</th>\n",
       "      <td>polito-WA1-AW1-2023</td>\n",
       "      <td>Courses at Politecnico di Torino - Academic Ye...</td>\n",
       "      <td>ITALIAN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>703</th>\n",
       "      <td>MOVIECORD</td>\n",
       "      <td>🎬 Movie | Film Festival | OTT</td>\n",
       "      <td>ITALIAN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1043</th>\n",
       "      <td>realme-mt6781-dev</td>\n",
       "      <td>AOSP Sources For Realme 8i/Narzo 50</td>\n",
       "      <td>ITALIAN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1054</th>\n",
       "      <td>ipfs</td>\n",
       "      <td>A peer-to-peer hypermedia protocol</td>\n",
       "      <td>ITALIAN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    login                                        description  \\\n",
       "390       xDroidOSS-Pixel                      Credit :  xdroidOSS (mnmlist)   \n",
       "403   polito-WA1-AW1-2023  Courses at Politecnico di Torino - Academic Ye...   \n",
       "703             MOVIECORD                      🎬 Movie | Film Festival | OTT   \n",
       "1043    realme-mt6781-dev                AOSP Sources For Realme 8i/Narzo 50   \n",
       "1054                 ipfs                 A peer-to-peer hypermedia protocol   \n",
       "\n",
       "     language  \n",
       "390   ITALIAN  \n",
       "403   ITALIAN  \n",
       "703   ITALIAN  \n",
       "1043  ITALIAN  \n",
       "1054  ITALIAN  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from lingua import Language, LanguageDetectorBuilder\n",
    "import pandas as pd\n",
    "\n",
    "df_lingua = df_orgs\n",
    "\n",
    "# Available languages\n",
    "languages = [Language.ENGLISH, Language.FRENCH, Language.GERMAN, Language.SPANISH, Language.ITALIAN]\n",
    "\n",
    "# Build the language detector\n",
    "detector = LanguageDetectorBuilder.from_languages(*languages).build()\n",
    "\n",
    "# Function to detect language\n",
    "def detect_language(text):\n",
    "    try:\n",
    "        return detector.detect_language_of(text).name\n",
    "    except:\n",
    "        return \"unknown\"\n",
    "\n",
    "# Apply the function to the 'description' column and store the result in a new column 'language'\n",
    "df_lingua['language'] = df_lingua['description'].apply(detect_language)\n",
    "\n",
    "# Display the DataFrame\n",
    "df_lingua[df_lingua[\"language\"]==\"ITALIAN\"].head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc165dec",
   "metadata": {},
   "source": [
    "### Langdetect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "28c45ead",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>login</th>\n",
       "      <th>description</th>\n",
       "      <th>language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>241</th>\n",
       "      <td>TYPO3-Documentation</td>\n",
       "      <td>Official TYPO3 Documentation</td>\n",
       "      <td>it</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>378</th>\n",
       "      <td>project-violet</td>\n",
       "      <td>Violation Violet</td>\n",
       "      <td>it</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>616</th>\n",
       "      <td>PositiveSumNet</td>\n",
       "      <td>non-commercial use</td>\n",
       "      <td>it</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>703</th>\n",
       "      <td>MOVIECORD</td>\n",
       "      <td>🎬 Movie | Film Festival | OTT</td>\n",
       "      <td>it</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>715</th>\n",
       "      <td>nomic-ai</td>\n",
       "      <td>democratizing access to powerful artificial in...</td>\n",
       "      <td>it</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1378</th>\n",
       "      <td>RR0</td>\n",
       "      <td>UFO data since 1998</td>\n",
       "      <td>it</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1455</th>\n",
       "      <td>CreaMate-Consulting</td>\n",
       "      <td>smart digital solutions</td>\n",
       "      <td>it</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1662</th>\n",
       "      <td>JuliaPlots</td>\n",
       "      <td>Data visualization in Julia</td>\n",
       "      <td>it</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1833</th>\n",
       "      <td>theia-ailabs</td>\n",
       "      <td>AI Voice Assistant</td>\n",
       "      <td>it</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1958</th>\n",
       "      <td>panoramicdata</td>\n",
       "      <td>Panoramic Data Limited</td>\n",
       "      <td>it</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2144</th>\n",
       "      <td>dripnillbyteskidrip</td>\n",
       "      <td>Official somalia devs</td>\n",
       "      <td>it</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2253</th>\n",
       "      <td>AppliedDataSciencePartners</td>\n",
       "      <td>A data science consultancy, delivering innovat...</td>\n",
       "      <td>it</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2966</th>\n",
       "      <td>bokeh</td>\n",
       "      <td>Interactive Data Visualization</td>\n",
       "      <td>it</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3025</th>\n",
       "      <td>EazyAutodelete</td>\n",
       "      <td>EazyAutodelete - A Discord Bot to automaticall...</td>\n",
       "      <td>it</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3217</th>\n",
       "      <td>doclingjs</td>\n",
       "      <td>Participatory design for language documentation</td>\n",
       "      <td>it</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3850</th>\n",
       "      <td>sangria-graphql</td>\n",
       "      <td>Sangria - Scala GraphQL implementation</td>\n",
       "      <td>it</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4024</th>\n",
       "      <td>useVenice</td>\n",
       "      <td>Frictionless financial data.</td>\n",
       "      <td>it</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4324</th>\n",
       "      <td>CMU-HKN</td>\n",
       "      <td>Eta Kappa Nu at Carnegie Mellon</td>\n",
       "      <td>it</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4559</th>\n",
       "      <td>rhasspy</td>\n",
       "      <td>Offline voice assistant</td>\n",
       "      <td>it</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4748</th>\n",
       "      <td>FNNDSC</td>\n",
       "      <td>Fetal-Neonatal Neuroimaging Developmental Scie...</td>\n",
       "      <td>it</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5285</th>\n",
       "      <td>Thorium-Sim</td>\n",
       "      <td>Next-generation space simulator controls</td>\n",
       "      <td>it</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5501</th>\n",
       "      <td>BSData</td>\n",
       "      <td>Home for BattleScribe datafiles (catalogues)</td>\n",
       "      <td>it</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5614</th>\n",
       "      <td>TdP-2023</td>\n",
       "      <td>Pagina ufficiale del corso di Tecniche di Prog...</td>\n",
       "      <td>it</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5646</th>\n",
       "      <td>mozilla-mobile</td>\n",
       "      <td>Mozilla Mobile Applications</td>\n",
       "      <td>it</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6279</th>\n",
       "      <td>piql</td>\n",
       "      <td>Reshaping digital preservation</td>\n",
       "      <td>it</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6409</th>\n",
       "      <td>Chaox-Community</td>\n",
       "      <td>We still prevail</td>\n",
       "      <td>it</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6543</th>\n",
       "      <td>PizzaDAO</td>\n",
       "      <td>pizza shud b free</td>\n",
       "      <td>it</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6705</th>\n",
       "      <td>vueComponent</td>\n",
       "      <td>vue component</td>\n",
       "      <td>it</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6840</th>\n",
       "      <td>ettle</td>\n",
       "      <td>Positive Intent</td>\n",
       "      <td>it</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6953</th>\n",
       "      <td>toml-f</td>\n",
       "      <td>A TOML parser implementation for data serializ...</td>\n",
       "      <td>it</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           login  \\\n",
       "241          TYPO3-Documentation   \n",
       "378               project-violet   \n",
       "616               PositiveSumNet   \n",
       "703                    MOVIECORD   \n",
       "715                     nomic-ai   \n",
       "1378                         RR0   \n",
       "1455         CreaMate-Consulting   \n",
       "1662                  JuliaPlots   \n",
       "1833                theia-ailabs   \n",
       "1958               panoramicdata   \n",
       "2144         dripnillbyteskidrip   \n",
       "2253  AppliedDataSciencePartners   \n",
       "2966                       bokeh   \n",
       "3025              EazyAutodelete   \n",
       "3217                   doclingjs   \n",
       "3850             sangria-graphql   \n",
       "4024                   useVenice   \n",
       "4324                     CMU-HKN   \n",
       "4559                     rhasspy   \n",
       "4748                      FNNDSC   \n",
       "5285                 Thorium-Sim   \n",
       "5501                      BSData   \n",
       "5614                    TdP-2023   \n",
       "5646              mozilla-mobile   \n",
       "6279                        piql   \n",
       "6409             Chaox-Community   \n",
       "6543                    PizzaDAO   \n",
       "6705                vueComponent   \n",
       "6840                       ettle   \n",
       "6953                      toml-f   \n",
       "\n",
       "                                            description language  \n",
       "241                        Official TYPO3 Documentation       it  \n",
       "378                                    Violation Violet       it  \n",
       "616                                  non-commercial use       it  \n",
       "703                       🎬 Movie | Film Festival | OTT       it  \n",
       "715   democratizing access to powerful artificial in...       it  \n",
       "1378                                UFO data since 1998       it  \n",
       "1455                            smart digital solutions       it  \n",
       "1662                        Data visualization in Julia       it  \n",
       "1833                                 AI Voice Assistant       it  \n",
       "1958                             Panoramic Data Limited       it  \n",
       "2144                              Official somalia devs       it  \n",
       "2253  A data science consultancy, delivering innovat...       it  \n",
       "2966                    Interactive Data Visualization        it  \n",
       "3025  EazyAutodelete - A Discord Bot to automaticall...       it  \n",
       "3217    Participatory design for language documentation       it  \n",
       "3850            Sangria - Scala GraphQL implementation        it  \n",
       "4024                       Frictionless financial data.       it  \n",
       "4324                    Eta Kappa Nu at Carnegie Mellon       it  \n",
       "4559                            Offline voice assistant       it  \n",
       "4748  Fetal-Neonatal Neuroimaging Developmental Scie...       it  \n",
       "5285           Next-generation space simulator controls       it  \n",
       "5501       Home for BattleScribe datafiles (catalogues)       it  \n",
       "5614  Pagina ufficiale del corso di Tecniche di Prog...       it  \n",
       "5646                        Mozilla Mobile Applications       it  \n",
       "6279                     Reshaping digital preservation       it  \n",
       "6409                                   We still prevail       it  \n",
       "6543                                  pizza shud b free       it  \n",
       "6705                                      vue component       it  \n",
       "6840                                    Positive Intent       it  \n",
       "6953  A TOML parser implementation for data serializ...       it  "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langdetect import detect\n",
    "\n",
    "df_langdetect = df_orgs\n",
    "\n",
    "# Function to detect language\n",
    "def detect_language(text):\n",
    "    try:\n",
    "        return detect(text)\n",
    "    except:\n",
    "        return \"unknown\"\n",
    "\n",
    "# Apply the function to the 'description' column and store the result in a new column 'language'\n",
    "df_langdetect['language'] = df_langdetect['description'].apply(detect_language)\n",
    "\n",
    "# Display the DataFrame\n",
    "df_langdetect[df_langdetect[\"language\"] == \"it\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "367cf6ca",
   "metadata": {},
   "source": [
    "## 7. Italian Open Source Licences\n",
    "Problem is, that the authors are italian but not living in Italy!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7fa598b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2Ami',\n",
       " 'Apivault',\n",
       " 'Arduino',\n",
       " 'Arduino Desk Weatherstation',\n",
       " 'Argon',\n",
       " 'Autocannon',\n",
       " 'Awesome Italia Open Source',\n",
       " 'Bootstrap Italia',\n",
       " 'Breathly',\n",
       " 'Cache Candidate']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "import re\n",
    "import os\n",
    "\n",
    "def get_and_process_github_readme(url, filename, token):\n",
    "    \"\"\"\n",
    "    Download the README.md from GitHub, save it, extract and return the names of repositories.\n",
    "    \n",
    "    Parameters:\n",
    "        url (str): The URL to the raw README.md on GitHub.\n",
    "        filename (str): The name to save the README.md as.\n",
    "        token (str): Your GitHub API token.\n",
    "        \n",
    "    Returns:\n",
    "        list: Extracted repository names.\n",
    "    \"\"\"\n",
    "    headers = {\n",
    "        \"Authorization\": f\"token {token}\",\n",
    "        \"Accept\": \"application/vnd.github.v3.raw\"\n",
    "    }\n",
    "    \n",
    "    # Step 1: Download the README.md from GitHub\n",
    "    response = requests.get(url, headers=headers)\n",
    "    \n",
    "    # Ensure the request was successful\n",
    "    if response.status_code == 200:\n",
    "        readme_content = response.text\n",
    "        \n",
    "        # Step 2: Process the saved file to extract repository names\n",
    "        name_pattern = re.compile(r'\\|\\s*(?:\\[(?P<link_name>.+?)\\]\\(.+?\\)|(?P<plain_name>[^\\|\\[\\]]+))\\s*\\|')\n",
    "        names = []\n",
    "        for line in readme_content.split('\\n'):\n",
    "            match = name_pattern.search(line)\n",
    "            if match:\n",
    "                name = (match.group('link_name') or match.group('plain_name')).strip()\n",
    "                if name and name.lower() not in [\"name\", \"----\", \"stack\", \"description\"]:\n",
    "                    names.append(name)\n",
    "        return names\n",
    "    else:\n",
    "        raise ConnectionError(f\"Failed to fetch README.md, status code: {response.status_code}\")\n",
    "\n",
    "# URL to the raw README.md on GitHub\n",
    "readme_url = \"https://github.com/italia-opensource/awesome-italia-opensource/raw/main/awesome/opensource/README.md\"\n",
    "\n",
    "# Filename to save the README.md as\n",
    "save_filename = \"github_readme.md\"\n",
    "\n",
    "# Execute the function and display the first 10 repository names\n",
    "Italian_OS_projects = get_and_process_github_readme(readme_url, save_filename, github_token)[1:]\n",
    "Italian_OS_projects[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2d26c01",
   "metadata": {},
   "source": [
    "## E-Mail ends with .it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2cbfbed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming you have a dataframe df with a \"payload\" column\n",
    "# Create a new dataframe with extracted commit information\n",
    "def extract_commit_info(payload):\n",
    "    if 'commits' in payload:\n",
    "        commits = payload['commits']\n",
    "        if commits:\n",
    "            first_commit = commits[0]\n",
    "            return {\n",
    "                'repository_id': payload.get('repository_id'),\n",
    "                'push_id': payload.get('push_id'),\n",
    "                'author_email': first_commit['author']['email'],\n",
    "                'author_name': first_commit['author']['name'],\n",
    "                'commit_message': first_commit['message'],\n",
    "                'commit_sha': first_commit['sha']\n",
    "            }\n",
    "    return None\n",
    "\n",
    "# Apply the function to the \"payload\" column to extract commit information\n",
    "df['commit_info'] = df['payload'].apply(extract_commit_info)\n",
    "\n",
    "# Create a new dataframe from the extracted information\n",
    "df_commit_info = df['commit_info'].apply(pd.Series)\n",
    "\n",
    "# Now df_commit_info contains the extracted commit information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02ce8273",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "italian_emails = df_commit_info.copy()\n",
    "\n",
    "#remove NANs\n",
    "italian_emails = italian_emails.dropna(subset=['author_email', 'author_name', 'repository_id'])\n",
    "\n",
    "italian_emails['author_email'] = italian_emails['author_email'].astype(str)\n",
    "\n",
    "filtered_df = italian_emails[italian_emails['author_email'].str.endswith('.it')]\n",
    "filtered_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5a81a51",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f9e6115e",
   "metadata": {},
   "source": [
    "## Extras"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e45a951",
   "metadata": {},
   "source": [
    "### downloading data for multiple days/hours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b87db6c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import gzip\n",
    "import pandas as pd\n",
    "import logging\n",
    "from typing import List, Union\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "BASE_URL = \"https://data.gharchive.org\"\n",
    "\n",
    "def ensure_directory_exists(dir_name: str) -> None:\n",
    "    \"\"\"Ensure the specified directory exists.\"\"\"\n",
    "    if not os.path.exists(dir_name):\n",
    "        os.makedirs(dir_name)\n",
    "\n",
    "def download_file(url: str, file_path: str) -> None:\n",
    "    \"\"\"Download file and save it to the specified path.\"\"\"\n",
    "    try:\n",
    "        response = requests.get(url, stream=True)\n",
    "        if response.status_code == 200:\n",
    "            with open(file_path, 'wb') as f:\n",
    "                for chunk in response.iter_content(chunk_size=128):\n",
    "                    f.write(chunk)\n",
    "        else:\n",
    "            logging.warning(f\"File not found: {url}\")\n",
    "    except requests.RequestException as e:\n",
    "        logging.error(f\"Failed to fetch {url}: {str(e)}\")\n",
    "\n",
    "def load_or_fetch_data(file_path: str, url: str) -> Union[pd.DataFrame, None]:\n",
    "    \"\"\"Load data from file or fetch from URL if not exists.\"\"\"\n",
    "    if os.path.exists(file_path):\n",
    "        logging.info(f\"File {file_path} already exists. Loading data.\")\n",
    "        with gzip.open(file_path, 'rt', encoding='utf-8') as gz:\n",
    "            return pd.read_json(gz, lines=True)\n",
    "    else:\n",
    "        logging.info(f\"File {file_path} not exists. Downloading from {url}\")\n",
    "        download_file(url, file_path)\n",
    "        if os.path.exists(file_path):\n",
    "            with gzip.open(file_path, 'rt', encoding='utf-8') as gz:\n",
    "                return pd.read_json(gz, lines=True)\n",
    "    return None\n",
    "\n",
    "def download_gh_archive(start_day: int, end_day: int, \n",
    "                        start_hour: int=0, end_hour: int=23,\n",
    "                        base_url: str=BASE_URL, data_dir: str='data') -> pd.DataFrame:\n",
    "    \"\"\"Download GitHub archive data for specified days and hours.\"\"\"\n",
    "    dfs = []\n",
    "    ensure_directory_exists(data_dir)\n",
    "    \n",
    "    for day in range(start_day, end_day + 1):\n",
    "        for hour in range(start_hour, end_hour + 1):\n",
    "            filename = f\"2023-04-{day:02d}-{hour}.json.gz\"\n",
    "            url = f\"{base_url}/{filename}\"\n",
    "            file_path = os.path.join(data_dir, filename)\n",
    "            \n",
    "            df = load_or_fetch_data(file_path, url)\n",
    "            if df is not None:\n",
    "                dfs.append(df)\n",
    "\n",
    "    return pd.concat(dfs, ignore_index=True) if dfs else pd.DataFrame()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15c8a747",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Record the start time\n",
    "start_time = time.time()\n",
    "#Define the start and end date-time\n",
    "start_date_time = \"2023-04-01 10\"  # Format: \"YYYY-MM-DD HH\"\n",
    "end_date_time = \"2023-04-01 12\"    # Format: \"YYYY-MM-DD HH\"\n",
    "# Extract day and hour from the date-time strings\n",
    "start_day = int(start_date_time.split(\"-\")[2].split()[0])\n",
    "start_hour = int(start_date_time.split()[1])\n",
    "end_day = int(end_date_time.split(\"-\")[2].split()[0])\n",
    "end_hour = int(end_date_time.split()[1])\n",
    "\n",
    "# Download data for the specified time frame\n",
    "df_big = download_gh_archive(start_day, end_day, start_hour, end_hour)\n",
    "\n",
    "# Record the end time and calculate the elapsed time\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "\n",
    "print(f\"Data from {start_date_time} to {end_date_time} loaded into DataFrame!\")\n",
    "print(f\"Time taken: {elapsed_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "206a9485",
   "metadata": {},
   "source": [
    "### Getting rid of Github Bot commits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56206ce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df = df[~df['actor'].apply(lambda x: x.get('login').endswith('[bot]'))]\n",
    "filtered_df.reset_index(drop=True, inplace=True)\n",
    "filtered_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c6590bf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py:light"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
